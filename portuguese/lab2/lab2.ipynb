{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2364a810",
   "metadata": {},
   "source": [
    "# Azure AI Foundry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a02bae",
   "metadata": {},
   "source": [
    "<center><img src=\"../../images/Azure-AI-Foundry_1600x900.jpg\" alt=\"Azure AI Foundry\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7a15a5",
   "metadata": {},
   "source": [
    "## Laboratório 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048dc4e5",
   "metadata": {},
   "source": [
    "Neste laboratório é explorar os serviços de AI presentes no Azure Foundry, este laboratório vai cobrir os seguintes serviços:\n",
    "- Speech\n",
    "- Language + Translator\n",
    "- Vision + Document \n",
    "- Content Safety\n",
    "\n",
    "Entendendo estes serviços podemos adicionar mais habilidades à nossas aplicações."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7617fed7",
   "metadata": {},
   "source": [
    "### Exercício 1 - Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f46c67f",
   "metadata": {},
   "source": [
    "O serviço Speech fornece recursos de conversão de fala para texto e texto para fala com um recurso Speech. Você pode transcrever fala para texto com alta precisão, produzir vozes naturais de texto para fala, traduzir áudio falado e usar reconhecimento de locutor durante conversas. Crie vozes personalizadas, adicione palavras específicas ao seu vocabulário base ou construa seus próprios modelos. Execute o Speech em qualquer lugar, na nuvem ou na borda em contêineres. É fácil habilitar fala em suas aplicações, ferramentas e dispositivos com a CLI do Speech, SDK do Speech e APIs REST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8e176c",
   "metadata": {},
   "source": [
    "Cenários comunis para uso do speech:\n",
    "\n",
    "**Geração de legenda:** Aprenda como sincronizar legendas com seu áudio de entrada, aplicar filtros de palavrões, obter resultados parciais, aplicar personalizações e identificar idiomas falados para cenários multilíngues.\n",
    "\n",
    "**Criação de Conteúdo de Áudio:** Você pode usar vozes neurais para tornar as interações com chatbots e assistentes de voz mais naturais e envolventes, converter textos digitais como e-books em audiolivros e aprimorar sistemas de navegação automotiva.\n",
    "\n",
    "**Central de Atendimento:** Transcreva chamadas em tempo real ou processe um lote de chamadas, remova informações de identificação pessoal e extraia insights como análise de sentimento para auxiliar no seu caso de uso de central de atendimento.\n",
    "\n",
    "**Aprendizado de Idiomas:** Forneça feedback de avaliação de pronúncia para estudantes de idiomas, ofereça suporte à transcrição em tempo real para conversas de aprendizado remoto e leia materiais didáticos em voz alta usando vozes neurais.\n",
    "\n",
    "**Assistentes de Voz:** Crie interfaces conversacionais naturais e semelhantes às humanas para suas aplicações e experiências. O recurso de assistente de voz oferece interação rápida e confiável entre um dispositivo e uma implementação de assistente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dea14b",
   "metadata": {},
   "source": [
    "Para realizar este exercício verifique se no seu arquivo `.env` possui as seguintes variaveis preenchidas:\n",
    "- SPEECH_ENDPOINT \n",
    "- SPEECH_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0237903",
   "metadata": {},
   "source": [
    "Após verificar vamos iniciar carregando as bibliotecas necessárias, iniciando o cliente e realizando uma chamada para converter audio em texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63856ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75304711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "# Configurar o cliente Speech\n",
    "speech_key = os.getenv('SPEECH_KEY')\n",
    "speech_endpoint = os.getenv('SPEECH_ENDPOINT')\n",
    "speech_region = os.getenv('SPEECH_REGION')\n",
    "\n",
    "# Configurar o Speech SDK\n",
    "speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "speech_config.speech_recognition_language = \"pt-BR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35da9a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_config = speechsdk.audio.AudioConfig(filename=\"../../samples/audio001.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71278663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando transcrição do áudio...\n"
     ]
    }
   ],
   "source": [
    "speech_recognizer = None\n",
    "\n",
    "# Criar o SpeechRecognizer usando endpoint (solução para SPXERR_INVALID_HEADER)\n",
    "speech_config_endpoint = speechsdk.SpeechConfig(endpoint=speech_endpoint, subscription=speech_key)\n",
    "speech_config_endpoint.speech_recognition_language = \"pt-BR\"\n",
    "\n",
    "speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config_endpoint, audio_config=audio_config)\n",
    "\n",
    "print(\"Iniciando transcrição do áudio...\")\n",
    "\n",
    "result = speech_recognizer.recognize_once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37caf3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nenhuma fala foi detectada no áudio.\n"
     ]
    }
   ],
   "source": [
    "if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "    print(f\"Transcrição: {result.text}\")\n",
    "elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "    print(\"Nenhuma fala foi detectada no áudio.\")\n",
    "elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = result.cancellation_details\n",
    "    print(f\"Reconhecimento cancelado: {cancellation_details.reason}\")\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        print(f\"Erro: {cancellation_details.error_details}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d0478c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85f8f57",
   "metadata": {},
   "source": [
    "### Exercício 2 - Language + Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8423f00",
   "metadata": {},
   "source": [
    "Integre linguagem natural em aplicativos, bots e dispositivos IoT. Por exemplo, este serviço pode remover dados sensíveis, segmentar reuniões longas em capítulos, analisar registros de saúde e orquestrar bots conversacionais com suas intenções personalizadas usando respostas factuais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464ad576",
   "metadata": {},
   "source": [
    "Este serviço de Linguagem unifica os seguintes serviços do Azure AI anteriormente disponíveis: Text Analytics, QnA Maker e LUIS.\n",
    "\n",
    "O Azure AI Foundry permite que você use a maioria dos seguintes recursos de serviço sem precisar escrever código.\n",
    "\n",
    "**Reconhecimento de Entidade Nomeada (NER)** - O reconhecimento de entidade nomeada identifica diferentes entradas no texto e as categoriza em tipos predefinidos.\n",
    "\n",
    "**Detecção de informações pessoais e de saúde** - A detecção de PII identifica entidades em texto e conversas (chat ou transcrições) que estão associadas a indivíduos.\n",
    "\n",
    "**Detecção de idioma** - A detecção de idioma avalia o texto e detecta uma ampla gama de idiomas e dialetos variantes.\n",
    "\n",
    "**Análise de sentimento e mineração de opinião** - A análise de sentimento e mineração de opinião são recursos pré-configurados que ajudam você a entender a percepção pública da sua marca ou tópico. Esses recursos analisam o texto para identificar sentimentos positivos ou negativos e podem vinculá-los a elementos específicos dentro do texto.\n",
    "\n",
    "**Sumarização** - A sumarização condensa informações para texto e conversas (chat e transcrições). A sumarização de texto gera um resumo, suportando duas abordagens: A sumarização extrativa cria um resumo selecionando frases-chave do documento e preservando suas posições originais. Em contraste, a sumarização abstrativa gera um resumo produzindo sentenças ou frases novas, concisas e coerentes que não são copiadas diretamente do documento original. A sumarização de conversa recapitula e segmenta reuniões longas em capítulos com marcação de tempo. A sumarização de call center resume problemas do cliente e suas resoluções.\n",
    "\n",
    "**Extração de frases-chave** - A extração de frases-chave é um recurso pré-configurado que avalia e retorna os principais conceitos em texto não estruturado, retornando-os como uma lista.\n",
    "\n",
    "**Vinculação de entidades** - A vinculação de entidades é um recurso pré-configurado que desambigua a identidade de entidades (palavras ou frases) encontradas em texto não estruturado e retorna links para a Wikipedia.\n",
    "\n",
    "**Análise de texto para saúde** - A análise de texto para saúde extrai e rotula informações relevantes de saúde de texto não estruturado.\n",
    "\n",
    "**Classificação de texto personalizada** - A classificação de texto personalizada permite que você construa modelos de IA personalizados para classificar documentos de texto não estruturado em classes personalizadas que você define.\n",
    "\n",
    "**Reconhecimento de Entidade Nomeada Personalizada (NER Personalizado)** - O NER personalizado permite que você construa modelos de IA personalizados para extrair categorias de entidades personalizadas (rótulos para palavras ou frases), usando texto não estruturado que você fornece.\n",
    "\n",
    "**Compreensão de linguagem conversacional** - A compreensão de linguagem conversacional (CLU) permite que os usuários construam modelos personalizados de compreensão de linguagem natural para prever a intenção geral de uma declaração recebida e extrair informações importantes dela.\n",
    "\n",
    "**Fluxo de trabalho de orquestração** - O fluxo de trabalho de orquestração é um recurso personalizado que permite conectar aplicações de Compreensão de Linguagem Conversacional (CLU), resposta a perguntas e LUIS.\n",
    "\n",
    "**Resposta a perguntas** - A resposta a perguntas é um recurso personalizado que identifica a resposta mais adequada para entradas do usuário. Este recurso é tipicamente utilizado para desenvolver aplicações cliente conversacionais, incluindo plataformas de mídia social, chat bots e aplicações desktop habilitadas por voz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca10f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d6d532d",
   "metadata": {},
   "source": [
    "### Exercício 3 - Vision + Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76352a97",
   "metadata": {},
   "source": [
    "Dê aos seus aplicativos a capacidade de ler texto, analisar imagens, processar documentos e detectar rostos com tecnologias como reconhecimento óptico de caracteres (OCR) e aprendizado de máquina."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453c8d42",
   "metadata": {},
   "source": [
    "O serviço Azure AI Vision oferece acesso a algoritmos avançados que processam imagens e retornam informações baseadas nas características visuais de seu interesse. A tabela a seguir lista as principais categorias de produtos.\n",
    "\n",
    "**Reconhecimento Óptico de Caracteres (OCR)** - O serviço de Reconhecimento Óptico de Caracteres (OCR) extrai texto de imagens. Você pode usar a API Read para extrair texto impresso e manuscrito de fotos e documentos. Ele utiliza modelos baseados em aprendizado profundo e funciona com texto em várias superfícies e fundos. Isso inclui documentos comerciais, faturas, recibos, cartazes, cartões de visita, cartas e quadros brancos. As APIs de OCR suportam a extração de texto impresso em vários idiomas.\n",
    "\n",
    "**Análise de Imagem** - O serviço de Análise de Imagem extrai muitas características visuais de imagens, como objetos, rostos, conteúdo adulto e descrições de texto geradas automaticamente.\n",
    "\n",
    "**Face** - O serviço Face fornece algoritmos de IA que detectam, reconhecem e analisam rostos humanos em imagens. O software de reconhecimento facial é importante em muitos cenários diferentes, como identificação, controle de acesso sem toque e desfoque facial para privacidade.\n",
    "\n",
    "**Recuperação de Vídeo** - A Recuperação de Vídeo permite criar um índice de vídeos que você pode pesquisar com linguagem natural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ef1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf190fab",
   "metadata": {},
   "source": [
    "### Exercício 4 - Content Safety"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded113b8",
   "metadata": {},
   "source": [
    "A segurança de conteúdo do Azure AI detecta conteúdo prejudicial gerado por usuários e por IA em aplicativos e serviços. Este serviço disponibiliza vários tipos diferentes de análise.\n",
    "\n",
    "**Escudos de Prompt** - Examina texto em busca de riscos de ataques de entrada do usuário em um Modelo de Linguagem Grande.\n",
    "\n",
    "**Detecção de fundamentação (preview)** - Detecta se as respostas de texto de modelos de linguagem grandes (LLMs) estão fundamentadas nos materiais fonte fornecidos pelos usuários.\n",
    "\n",
    "**Detecção de material protegido em texto** - Examina texto gerado por IA em busca de conteúdo de texto conhecido (por exemplo, letras de música, artigos, receitas, conteúdo web selecionado).\n",
    "\n",
    "**API de categorias personalizadas (padrão) (preview)** - Permite criar e treinar suas próprias categorias de conteúdo personalizadas e examinar texto em busca de correspondências.\n",
    "\n",
    "**API de categorias personalizadas (rápida) (preview)** - Permite definir padrões emergentes de conteúdo prejudicial e examinar texto e imagens em busca de correspondências.\n",
    "\n",
    "**API de análise de texto** - Examina texto em busca de conteúdo sexual, violência, ódio e autolesão com múltiplos níveis de severidade.\n",
    "\n",
    "**API de análise de imagem** - Examina imagens em busca de conteúdo sexual, violência, ódio e autolesão com múltiplos níveis de severidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9045f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

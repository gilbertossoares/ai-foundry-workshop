{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2364a810",
   "metadata": {},
   "source": [
    "# Azure AI Foundry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a02bae",
   "metadata": {},
   "source": [
    "<center><img src=\"../../../images/Azure-AI-Foundry_1600x900.jpg\" alt=\"Azure AI Foundry\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7a15a5",
   "metadata": {},
   "source": [
    "## Laborat√≥rio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048dc4e5",
   "metadata": {},
   "source": [
    "Neste laborat√≥rio √© explorar os servi√ßos de AI presentes no Azure Foundry, este laborat√≥rio vai cobrir os seguintes servi√ßos:\n",
    "- Speech\n",
    "- Language + Translator\n",
    "- Vision + Document \n",
    "- Content Safety\n",
    "\n",
    "Entendendo estes servi√ßos podemos adicionar mais habilidades √† nossas aplica√ß√µes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7617fed7",
   "metadata": {},
   "source": [
    "### Exerc√≠cio 1 - Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f46c67f",
   "metadata": {},
   "source": [
    "O servi√ßo Speech fornece recursos de convers√£o de fala para texto e texto para fala com um recurso Speech. Voc√™ pode transcrever fala para texto com alta precis√£o, produzir vozes naturais de texto para fala, traduzir √°udio falado e usar reconhecimento de locutor durante conversas. Crie vozes personalizadas, adicione palavras espec√≠ficas ao seu vocabul√°rio base ou construa seus pr√≥prios modelos. Execute o Speech em qualquer lugar, na nuvem ou na borda em cont√™ineres. √â f√°cil habilitar fala em suas aplica√ß√µes, ferramentas e dispositivos com a CLI do Speech, SDK do Speech e APIs REST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8e176c",
   "metadata": {},
   "source": [
    "Cen√°rios comunis para uso do speech:\n",
    "\n",
    "**Gera√ß√£o de legenda:** Aprenda como sincronizar legendas com seu √°udio de entrada, aplicar filtros de palavr√µes, obter resultados parciais, aplicar personaliza√ß√µes e identificar idiomas falados para cen√°rios multil√≠ngues.\n",
    "\n",
    "**Cria√ß√£o de Conte√∫do de √Åudio:** Voc√™ pode usar vozes neurais para tornar as intera√ß√µes com chatbots e assistentes de voz mais naturais e envolventes, converter textos digitais como e-books em audiolivros e aprimorar sistemas de navega√ß√£o automotiva.\n",
    "\n",
    "**Central de Atendimento:** Transcreva chamadas em tempo real ou processe um lote de chamadas, remova informa√ß√µes de identifica√ß√£o pessoal e extraia insights como an√°lise de sentimento para auxiliar no seu caso de uso de central de atendimento.\n",
    "\n",
    "**Aprendizado de Idiomas:** Forne√ßa feedback de avalia√ß√£o de pron√∫ncia para estudantes de idiomas, ofere√ßa suporte √† transcri√ß√£o em tempo real para conversas de aprendizado remoto e leia materiais did√°ticos em voz alta usando vozes neurais.\n",
    "\n",
    "**Assistentes de Voz:** Crie interfaces conversacionais naturais e semelhantes √†s humanas para suas aplica√ß√µes e experi√™ncias. O recurso de assistente de voz oferece intera√ß√£o r√°pida e confi√°vel entre um dispositivo e uma implementa√ß√£o de assistente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dea14b",
   "metadata": {},
   "source": [
    "Para realizar este exerc√≠cio verifique se no seu arquivo `.env` possui as seguintes variaveis preenchidas:\n",
    "- SPEECH_ENDPOINT \n",
    "- SPEECH_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0237903",
   "metadata": {},
   "source": [
    "Ap√≥s verificar vamos iniciar carregando as bibliotecas necess√°rias, iniciando o cliente e realizando uma chamada para converter audio em texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea88da5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-cognitiveservices-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a68310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconhecimento cont√≠nuo de fala para processar todo o √°udio, mesmo com sil√™ncio inicial\n",
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "speech_key = os.getenv('SPEECH_KEY')\n",
    "speech_region = os.getenv('SPEECH_REGION')\n",
    "audio_file = '../../../samples/audio001.wav'\n",
    "if speech_key and speech_region:\n",
    "    try:\n",
    "        speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "        speech_config.speech_recognition_language = \"pt-BR\"\n",
    "        audio_config = speechsdk.audio.AudioConfig(filename=audio_file)\n",
    "        speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "        recognized_texts = []\n",
    "        def recognized_cb(evt):\n",
    "            if evt.result.text:\n",
    "                print('Reconhecido:', evt.result.text)\n",
    "                recognized_texts.append(evt.result.text)\n",
    "\n",
    "        speech_recognizer.recognized.connect(recognized_cb)\n",
    "\n",
    "        print(\"Iniciando reconhecimento cont√≠nuo...\")\n",
    "        speech_recognizer.start_continuous_recognition()\n",
    "\n",
    "        # Aguarda o reconhecimento terminar (ajuste o tempo conforme o tamanho do √°udio)\n",
    "        time.sleep(10)\n",
    "        speech_recognizer.stop_continuous_recognition()\n",
    "\n",
    "        print(\"Reconhecimento finalizado. Texto completo:\")\n",
    "        print(' '.join(recognized_texts))\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no reconhecimento cont√≠nuo: {e}\")\n",
    "else:\n",
    "    print(\"Por favor, configure as vari√°veis de ambiente SPEECH_KEY e SPEECH_REGION.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85f8f57",
   "metadata": {},
   "source": [
    "### Exerc√≠cio 2 - Language + Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8423f00",
   "metadata": {},
   "source": [
    "Integre linguagem natural em aplicativos, bots e dispositivos IoT. Por exemplo, este servi√ßo pode remover dados sens√≠veis, segmentar reuni√µes longas em cap√≠tulos, analisar registros de sa√∫de e orquestrar bots conversacionais com suas inten√ß√µes personalizadas usando respostas factuais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464ad576",
   "metadata": {},
   "source": [
    "Este servi√ßo de Linguagem unifica os seguintes servi√ßos do Azure AI anteriormente dispon√≠veis: Text Analytics, QnA Maker e LUIS.\n",
    "\n",
    "O Azure AI Foundry permite que voc√™ use a maioria dos seguintes recursos de servi√ßo sem precisar escrever c√≥digo.\n",
    "\n",
    "**Reconhecimento de Entidade Nomeada (NER)** - O reconhecimento de entidade nomeada identifica diferentes entradas no texto e as categoriza em tipos predefinidos.\n",
    "\n",
    "**Detec√ß√£o de informa√ß√µes pessoais e de sa√∫de** - A detec√ß√£o de PII identifica entidades em texto e conversas (chat ou transcri√ß√µes) que est√£o associadas a indiv√≠duos.\n",
    "\n",
    "**Detec√ß√£o de idioma** - A detec√ß√£o de idioma avalia o texto e detecta uma ampla gama de idiomas e dialetos variantes.\n",
    "\n",
    "**An√°lise de sentimento e minera√ß√£o de opini√£o** - A an√°lise de sentimento e minera√ß√£o de opini√£o s√£o recursos pr√©-configurados que ajudam voc√™ a entender a percep√ß√£o p√∫blica da sua marca ou t√≥pico. Esses recursos analisam o texto para identificar sentimentos positivos ou negativos e podem vincul√°-los a elementos espec√≠ficos dentro do texto.\n",
    "\n",
    "**Sumariza√ß√£o** - A sumariza√ß√£o condensa informa√ß√µes para texto e conversas (chat e transcri√ß√µes). A sumariza√ß√£o de texto gera um resumo, suportando duas abordagens: A sumariza√ß√£o extrativa cria um resumo selecionando frases-chave do documento e preservando suas posi√ß√µes originais. Em contraste, a sumariza√ß√£o abstrativa gera um resumo produzindo senten√ßas ou frases novas, concisas e coerentes que n√£o s√£o copiadas diretamente do documento original. A sumariza√ß√£o de conversa recapitula e segmenta reuni√µes longas em cap√≠tulos com marca√ß√£o de tempo. A sumariza√ß√£o de call center resume problemas do cliente e suas resolu√ß√µes.\n",
    "\n",
    "**Extra√ß√£o de frases-chave** - A extra√ß√£o de frases-chave √© um recurso pr√©-configurado que avalia e retorna os principais conceitos em texto n√£o estruturado, retornando-os como uma lista.\n",
    "\n",
    "**Vincula√ß√£o de entidades** - A vincula√ß√£o de entidades √© um recurso pr√©-configurado que desambigua a identidade de entidades (palavras ou frases) encontradas em texto n√£o estruturado e retorna links para a Wikipedia.\n",
    "\n",
    "**An√°lise de texto para sa√∫de** - A an√°lise de texto para sa√∫de extrai e rotula informa√ß√µes relevantes de sa√∫de de texto n√£o estruturado.\n",
    "\n",
    "**Classifica√ß√£o de texto personalizada** - A classifica√ß√£o de texto personalizada permite que voc√™ construa modelos de IA personalizados para classificar documentos de texto n√£o estruturado em classes personalizadas que voc√™ define.\n",
    "\n",
    "**Reconhecimento de Entidade Nomeada Personalizada (NER Personalizado)** - O NER personalizado permite que voc√™ construa modelos de IA personalizados para extrair categorias de entidades personalizadas (r√≥tulos para palavras ou frases), usando texto n√£o estruturado que voc√™ fornece.\n",
    "\n",
    "**Compreens√£o de linguagem conversacional** - A compreens√£o de linguagem conversacional (CLU) permite que os usu√°rios construam modelos personalizados de compreens√£o de linguagem natural para prever a inten√ß√£o geral de uma declara√ß√£o recebida e extrair informa√ß√µes importantes dela.\n",
    "\n",
    "**Fluxo de trabalho de orquestra√ß√£o** - O fluxo de trabalho de orquestra√ß√£o √© um recurso personalizado que permite conectar aplica√ß√µes de Compreens√£o de Linguagem Conversacional (CLU), resposta a perguntas e LUIS.\n",
    "\n",
    "**Resposta a perguntas** - A resposta a perguntas √© um recurso personalizado que identifica a resposta mais adequada para entradas do usu√°rio. Este recurso √© tipicamente utilizado para desenvolver aplica√ß√µes cliente conversacionais, incluindo plataformas de m√≠dia social, chat bots e aplica√ß√µes desktop habilitadas por voz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04b72b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure.ai.textanalytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca10f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo - Language Service\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Configurar o cliente Language\n",
    "language_endpoint = os.getenv('AZURE_LANGUAGE_ENDPOINT')\n",
    "language_key = os.getenv('AZURE_LANGUAGE_KEY')\n",
    "\n",
    "if language_endpoint and language_key:\n",
    "    # Criar cliente\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "        endpoint=language_endpoint,\n",
    "        credential=AzureKeyCredential(language_key)\n",
    "    )\n",
    "    \n",
    "    # Texto de exemplo\n",
    "    documents = [\n",
    "        \"Eu amo este produto! √â incr√≠vel e funciona perfeitamente.\",\n",
    "        \"Este servi√ßo √© terr√≠vel, n√£o funcionou como esperado.\",\n",
    "        \"O atendimento foi adequado, nada excepcional.\"\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # An√°lise de sentimento\n",
    "        response = text_analytics_client.analyze_sentiment(documents=documents, language=\"pt\")\n",
    "        \n",
    "        print(\"=== An√°lise de Sentimento ===\")\n",
    "        for idx, doc in enumerate(response):\n",
    "            if not doc.is_error:\n",
    "                print(f\"Documento {idx + 1}:\")\n",
    "                print(f\"  Texto: {documents[idx]}\")\n",
    "                print(f\"  Sentimento: {doc.sentiment}\")\n",
    "                print(f\"  Confian√ßa: Positivo={doc.confidence_scores.positive:.2f}, \"\n",
    "                      f\"Neutro={doc.confidence_scores.neutral:.2f}, \"\n",
    "                      f\"Negativo={doc.confidence_scores.negative:.2f}\")\n",
    "                print()\n",
    "            else:\n",
    "                print(f\"Erro no documento {idx + 1}: {doc.error}\")\n",
    "                \n",
    "        # Extra√ß√£o de frases-chave\n",
    "        key_phrases_response = text_analytics_client.extract_key_phrases(documents=documents, language=\"pt\")\n",
    "        \n",
    "        print(\"=== Extra√ß√£o de Frases-Chave ===\")\n",
    "        for idx, doc in enumerate(key_phrases_response):\n",
    "            if not doc.is_error:\n",
    "                print(f\"Documento {idx + 1}:\")\n",
    "                print(f\"  Frases-chave: {', '.join(doc.key_phrases)}\")\n",
    "                print()\n",
    "            else:\n",
    "                print(f\"Erro no documento {idx + 1}: {doc.error}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Erro: {e}\")\n",
    "else:\n",
    "    print(\"Defina as vari√°veis LANGUAGE_ENDPOINT e LANGUAGE_KEY no arquivo .env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6d532d",
   "metadata": {},
   "source": [
    "### Exerc√≠cio 3 - Vision + Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76352a97",
   "metadata": {},
   "source": [
    "D√™ aos seus aplicativos a capacidade de ler texto, analisar imagens, processar documentos e detectar rostos com tecnologias como reconhecimento √≥ptico de caracteres (OCR) e aprendizado de m√°quina."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453c8d42",
   "metadata": {},
   "source": [
    "O servi√ßo Azure AI Vision oferece acesso a algoritmos avan√ßados que processam imagens e retornam informa√ß√µes baseadas nas caracter√≠sticas visuais de seu interesse. A tabela a seguir lista as principais categorias de produtos.\n",
    "\n",
    "**Reconhecimento √ìptico de Caracteres (OCR)** - O servi√ßo de Reconhecimento √ìptico de Caracteres (OCR) extrai texto de imagens. Voc√™ pode usar a API Read para extrair texto impresso e manuscrito de fotos e documentos. Ele utiliza modelos baseados em aprendizado profundo e funciona com texto em v√°rias superf√≠cies e fundos. Isso inclui documentos comerciais, faturas, recibos, cartazes, cart√µes de visita, cartas e quadros brancos. As APIs de OCR suportam a extra√ß√£o de texto impresso em v√°rios idiomas.\n",
    "\n",
    "**An√°lise de Imagem** - O servi√ßo de An√°lise de Imagem extrai muitas caracter√≠sticas visuais de imagens, como objetos, rostos, conte√∫do adulto e descri√ß√µes de texto geradas automaticamente.\n",
    "\n",
    "**Face** - O servi√ßo Face fornece algoritmos de IA que detectam, reconhecem e analisam rostos humanos em imagens. O software de reconhecimento facial √© importante em muitos cen√°rios diferentes, como identifica√ß√£o, controle de acesso sem toque e desfoque facial para privacidade.\n",
    "\n",
    "**Recupera√ß√£o de V√≠deo** - A Recupera√ß√£o de V√≠deo permite criar um √≠ndice de v√≠deos que voc√™ pode pesquisar com linguagem natural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ef1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Configurar o cliente Vision\n",
    "vision_endpoint = os.getenv('AZURE_VISION_ENDPOINT')\n",
    "vision_key = os.getenv('AZURE_VISION_KEY')\n",
    "\n",
    "if vision_endpoint and vision_key:\n",
    "    try:\n",
    "        print(\"=== Azure AI Vision - An√°lise de Imagem ===\")\n",
    "        \n",
    "        # Criar cliente\n",
    "        client = ImageAnalysisClient(\n",
    "            endpoint=vision_endpoint,\n",
    "            credential=AzureKeyCredential(vision_key)\n",
    "        )\n",
    "        \n",
    "        # Analisar imagem remota\n",
    "        print(\"\\n1. Analisando imagem remota...\")\n",
    "        result = client.analyze_from_url(\n",
    "            image_url=\"https://learn.microsoft.com/azure/ai-services/computer-vision/media/quickstarts/presentation.png\",\n",
    "            visual_features=[VisualFeatures.CAPTION, VisualFeatures.READ],\n",
    "            gender_neutral_caption=True,  # Opcional (default √© False)\n",
    "        )\n",
    "        \n",
    "        print(\"Resultados da an√°lise:\")\n",
    "        \n",
    "        # Exibir resultados de legenda\n",
    "        print(\"\\nüìù Legenda:\")\n",
    "        if result.caption is not None:\n",
    "            print(f\"   '{result.caption.text}', Confian√ßa: {result.caption.confidence:.4f}\")\n",
    "        else:\n",
    "            print(\"   Nenhuma legenda encontrada\")\n",
    "\n",
    "        # Exibir resultados de OCR (texto extra√≠do)\n",
    "        print(\"\\nüìñ Texto extra√≠do (OCR):\")\n",
    "        if result.read is not None:\n",
    "            for block in result.read.blocks:\n",
    "                for line in block.lines:\n",
    "                    print(f\"   Linha: '{line.text}', Caixa delimitadora: {line.bounding_polygon}\")\n",
    "                    for word in line.words:\n",
    "                        print(f\"     Palavra: '{word.text}', Confian√ßa: {word.confidence:.4f}\")\n",
    "        else:\n",
    "            print(\"   Nenhum texto encontrado\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erro na an√°lise da imagem: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Defina as vari√°veis AZURE_VISION_ENDPOINT e AZURE_VISION_KEY no arquivo .env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaf98a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo avan√ßado - An√°lise completa de imagem local\n",
    "if vision_endpoint and vision_key:\n",
    "    try:\n",
    "        print(\"\\n=== An√°lise Avan√ßada de Imagem ===\")\n",
    "        \n",
    "        # Analisar imagem local\n",
    "        image_path = \"../../../samples/car-accident.png\"\n",
    "        \n",
    "        print(f\"\\n2. Analisando imagem local: {image_path}\")\n",
    "        \n",
    "        # Abrir imagem local\n",
    "        with open(image_path, \"rb\") as image_data:\n",
    "            # An√°lise completa com m√∫ltiplas funcionalidades\n",
    "            result = client.analyze(\n",
    "                image_data=image_data.read(),\n",
    "                visual_features=[\n",
    "                    VisualFeatures.CAPTION,\n",
    "                    VisualFeatures.READ,\n",
    "                    VisualFeatures.TAGS,\n",
    "                    VisualFeatures.OBJECTS,\n",
    "                    VisualFeatures.PEOPLE,\n",
    "                    VisualFeatures.SMART_CROPS\n",
    "                ],\n",
    "                gender_neutral_caption=True\n",
    "            )\n",
    "            \n",
    "            print(\"\\nüìù Legenda:\")\n",
    "            if result.caption:\n",
    "                print(f\"   '{result.caption.text}', Confian√ßa: {result.caption.confidence:.4f}\")\n",
    "            \n",
    "            print(\"\\nüè∑Ô∏è  Tags identificadas:\")\n",
    "            if result.tags:\n",
    "                for tag in result.tags.list:\n",
    "                    print(f\"   - {tag.name}: {tag.confidence:.4f}\")\n",
    "            \n",
    "            print(\"\\nüì¶ Objetos detectados:\")\n",
    "            if result.objects:\n",
    "                for obj in result.objects.list:\n",
    "                    print(f\"   - {obj.tags[0].name}: {obj.tags[0].confidence:.4f}\")\n",
    "                    print(f\"     Localiza√ß√£o: {obj.bounding_box}\")\n",
    "            \n",
    "            print(\"\\nüë• Pessoas detectadas:\")\n",
    "            if result.people:\n",
    "                for person in result.people.list:\n",
    "                    print(f\"   - Pessoa detectada com confian√ßa: {person.confidence:.4f}\")\n",
    "                    print(f\"     Localiza√ß√£o: {person.bounding_box}\")\n",
    "            \n",
    "            print(\"\\n‚úÇÔ∏è  Recortes inteligentes:\")\n",
    "            if result.smart_crops:\n",
    "                for crop in result.smart_crops.list:\n",
    "                    print(f\"   - Aspecto {crop.aspect_ratio}: {crop.bounding_box}\")\n",
    "                    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Arquivo de imagem n√£o encontrado: {image_path}\")\n",
    "        print(\"Certifique-se de que o arquivo existe no caminho especificado.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na an√°lise avan√ßada: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e1ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo - An√°lise de diferentes tipos de imagens\n",
    "if vision_endpoint and vision_key:\n",
    "    try:\n",
    "        print(\"\\n=== Compara√ß√£o de An√°lises de Diferentes Imagens ===\")\n",
    "        \n",
    "        # Lista de imagens para analisar\n",
    "        images_to_analyze = [\n",
    "            {\n",
    "                \"url\": \"https://learn.microsoft.com/azure/ai-services/computer-vision/media/quickstarts/presentation.png\",\n",
    "                \"description\": \"Apresenta√ß√£o de calend√°rio\"\n",
    "            },\n",
    "            {\n",
    "                \"url\": \"https://images.unsplash.com/photo-1518791841217-8f162f1e1131?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1000&q=80\",\n",
    "                \"description\": \"Gato\"\n",
    "            },\n",
    "            {\n",
    "                \"url\": \"https://images.unsplash.com/photo-1506905925346-21bda4d32df4?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1000&q=80\",\n",
    "                \"description\": \"Paisagem montanhosa\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        for i, image_info in enumerate(images_to_analyze, 1):\n",
    "            print(f\"\\n{i}. Analisando: {image_info['description']}\")\n",
    "            print(f\"   URL: {image_info['url']}\")\n",
    "            \n",
    "            try:\n",
    "                # An√°lise focada em legenda e tags\n",
    "                result = client.analyze_from_url(\n",
    "                    image_url=image_info[\"url\"],\n",
    "                    visual_features=[VisualFeatures.CAPTION, VisualFeatures.TAGS],\n",
    "                    gender_neutral_caption=True\n",
    "                )\n",
    "                \n",
    "                if result.caption:\n",
    "                    print(f\"   üìù Legenda: '{result.caption.text}' (Confian√ßa: {result.caption.confidence:.4f})\")\n",
    "                \n",
    "                if result.tags:\n",
    "                    print(\"   üè∑Ô∏è  Top 5 tags:\")\n",
    "                    for tag in result.tags.list[:5]:\n",
    "                        print(f\"      - {tag.name}: {tag.confidence:.4f}\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Erro ao analisar imagem {i}: {e}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Erro geral na an√°lise comparativa: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1808bb",
   "metadata": {},
   "source": [
    "#### Funcionalidades do Azure AI Vision\n",
    "\n",
    "O Azure AI Vision oferece v√°rias funcionalidades atrav√©s do SDK `azure-ai-vision-imageanalysis`:\n",
    "\n",
    "**üìù Funcionalidades Principais:**\n",
    "- **CAPTION**: Gera legendas descritivas para imagens\n",
    "- **READ**: Extrai texto de imagens (OCR)\n",
    "- **TAGS**: Identifica objetos, conceitos e a√ß√µes na imagem\n",
    "- **OBJECTS**: Detecta e localiza objetos espec√≠ficos\n",
    "- **PEOPLE**: Identifica pessoas na imagem\n",
    "- **SMART_CROPS**: Sugere recortes inteligentes da imagem\n",
    "- **FACES**: Detecta e analisa rostos (funcionalidade separada)\n",
    "\n",
    "**üìä M√©todos de An√°lise:**\n",
    "- `analyze_from_url()`: Analisa imagem de uma URL\n",
    "- `analyze()`: Analisa imagem de dados bin√°rios (arquivo local)\n",
    "\n",
    "**‚öôÔ∏è Par√¢metros Importantes:**\n",
    "- `visual_features`: Lista de funcionalidades a serem analisadas\n",
    "- `gender_neutral_caption`: Gera legendas neutras em g√™nero\n",
    "- `language`: Idioma para os resultados (padr√£o: ingl√™s)\n",
    "- `smart_crops_aspect_ratios`: Propor√ß√µes para recortes inteligentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4cd641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ Exerc√≠cio Pr√°tico - Teste suas pr√≥prias imagens\n",
    "if vision_endpoint and vision_key:\n",
    "    print(\"=== Exerc√≠cio Pr√°tico ===\")\n",
    "    print(\"\\nüìù Instru√ß√µes:\")\n",
    "    print(\"1. Substitua a URL abaixo por uma imagem de sua escolha\")\n",
    "    print(\"2. Escolha as funcionalidades que deseja testar\")\n",
    "    print(\"3. Execute a c√©lula e analise os resultados\")\n",
    "    \n",
    "    # üéØ MODIFIQUE AQUI: Cole a URL de uma imagem para testar\n",
    "    your_image_url = \"https://images.unsplash.com/photo-1544947950-fa07a98d237f?ixlib=rb-4.0.3&auto=format&fit=crop&w=800&q=80\"\n",
    "    \n",
    "    # üéØ MODIFIQUE AQUI: Escolha as funcionalidades que deseja testar\n",
    "    selected_features = [\n",
    "        VisualFeatures.CAPTION,\n",
    "        VisualFeatures.TAGS,\n",
    "        VisualFeatures.OBJECTS,\n",
    "        # VisualFeatures.READ,          # Descomente para OCR\n",
    "        # VisualFeatures.PEOPLE,        # Descomente para detectar pessoas\n",
    "        # VisualFeatures.SMART_CROPS,   # Descomente para recortes inteligentes\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\nüîç Analisando sua imagem...\")\n",
    "        print(f\"URL: {your_image_url}\")\n",
    "        \n",
    "        result = client.analyze_from_url(\n",
    "            image_url=your_image_url,\n",
    "            visual_features=selected_features,\n",
    "            gender_neutral_caption=True\n",
    "        )\n",
    "        \n",
    "        # Resultados\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"üéâ RESULTADOS DA SUA AN√ÅLISE\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        if result.caption:\n",
    "            print(f\"\\nüìù LEGENDA:\")\n",
    "            print(f\"   '{result.caption.text}'\")\n",
    "            print(f\"   Confian√ßa: {result.caption.confidence:.2%}\")\n",
    "        \n",
    "        if result.tags:\n",
    "            print(f\"\\nüè∑Ô∏è  TAGS IDENTIFICADAS:\")\n",
    "            for i, tag in enumerate(result.tags.list[:10], 1):\n",
    "                print(f\"   {i:2d}. {tag.name:<20} {tag.confidence:.2%}\")\n",
    "        \n",
    "        if result.objects:\n",
    "            print(f\"\\nüì¶ OBJETOS DETECTADOS:\")\n",
    "            for i, obj in enumerate(result.objects.list, 1):\n",
    "                print(f\"   {i}. {obj.tags[0].name} (Confian√ßa: {obj.tags[0].confidence:.2%})\")\n",
    "        \n",
    "        if result.read:\n",
    "            print(f\"\\nüìñ TEXTO EXTRA√çDO:\")\n",
    "            for block in result.read.blocks:\n",
    "                for line in block.lines:\n",
    "                    print(f\"   '{line.text}'\")\n",
    "        \n",
    "        if result.people:\n",
    "            print(f\"\\nüë• PESSOAS DETECTADAS: {len(result.people.list)} pessoa(s)\")\n",
    "        \n",
    "        if result.smart_crops:\n",
    "            print(f\"\\n‚úÇÔ∏è  RECORTES SUGERIDOS: {len(result.smart_crops.list)} op√ß√£o(√µes)\")\n",
    "            \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Erro ao analisar sua imagem: {e}\")\n",
    "        print(\"Verifique se a URL da imagem est√° correta e acess√≠vel.\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Configure as vari√°veis de ambiente AZURE_VISION_ENDPOINT e AZURE_VISION_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4065675",
   "metadata": {},
   "source": [
    "#### üéì Pr√≥ximos Passos\n",
    "\n",
    "**üìö Documenta√ß√£o e Recursos:**\n",
    "- [Documenta√ß√£o Oficial do Azure AI Vision](https://learn.microsoft.com/azure/ai-services/computer-vision/)\n",
    "- [Guia Completo da API de An√°lise de Imagem 4.0](https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/call-analyze-image-40)\n",
    "- [Refer√™ncia do SDK Python](https://aka.ms/azsdk/image-analysis/ref-docs/python)\n",
    "- [Amostras de C√≥digo no GitHub](https://aka.ms/azsdk/image-analysis/samples/python)\n",
    "\n",
    "**üõ†Ô∏è Experimente Tamb√©m:**\n",
    "- [Azure AI Vision Studio](https://portal.vision.cognitive.azure.com/) - Interface visual para testar recursos\n",
    "- [Azure AI Face Service](https://azure.microsoft.com/services/cognitive-services/face/) - An√°lise facial avan√ßada\n",
    "- [Azure AI Custom Vision](https://www.customvision.ai/) - Treinamento de modelos personalizados\n",
    "- [Azure AI Video Indexer](https://www.videoindexer.ai/) - An√°lise de v√≠deos\n",
    "\n",
    "**üíª Projetos Pr√°ticos Sugeridos:**\n",
    "1. **Descritor de Imagens para Acessibilidade**: Crie um site que gera alt-text autom√°tico\n",
    "2. **Analisador de Documentos**: Extraia texto de faturas e documentos\n",
    "3. **Moderador de Conte√∫do**: Sistema para classificar imagens automaticamente\n",
    "4. **Assistente Visual**: Aplicativo mobile que descreve o ambiente ao redor\n",
    "\n",
    "**üîÑ Integra√ß√£o com Outros Servi√ßos:**\n",
    "- Combine com Azure AI Language para an√°lise de sentimento do texto extra√≠do\n",
    "- Use com Azure AI Translator para tradu√ß√£o autom√°tica de texto em imagens\n",
    "- Integre com Azure Storage para processamento em lote\n",
    "- Conecte com Power BI para dashboards de insights visuais\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf1ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo - Document Intelligence\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Configurar cliente Document Intelligence\n",
    "doc_intelligence_endpoint = os.getenv('DOC_INTELLIGENCE_ENDPOINT')\n",
    "doc_intelligence_key = os.getenv('DOC_INTELLIGENCE_KEY')\n",
    "\n",
    "if doc_intelligence_endpoint and doc_intelligence_key:\n",
    "    try:\n",
    "        print(\"\\n=== Document Intelligence ===\")\n",
    "        \n",
    "        # Criar cliente\n",
    "        document_analysis_client = DocumentAnalysisClient(\n",
    "            endpoint=doc_intelligence_endpoint,\n",
    "            credential=AzureKeyCredential(doc_intelligence_key)\n",
    "        )\n",
    "        \n",
    "        # Analisar documento gen√©rico\n",
    "        doc_path = \"../../../samples/placa.jpg\"\n",
    "        \n",
    "        with open(doc_path, \"rb\") as f:\n",
    "            # Usar modelo pr√©-constru√≠do para layout geral\n",
    "            poller = document_analysis_client.begin_analyze_document(\n",
    "                \"prebuilt-layout\", document=f\n",
    "            )\n",
    "            \n",
    "        result = poller.result()\n",
    "        \n",
    "        print(\"An√°lise de Layout do Documento:\")\n",
    "        print(f\"N√∫mero de p√°ginas: {len(result.pages)}\")\n",
    "        \n",
    "        # Extrair tabelas\n",
    "        if result.tables:\n",
    "            print(f\"\\nTabelas encontradas: {len(result.tables)}\")\n",
    "            for idx, table in enumerate(result.tables):\n",
    "                print(f\"Tabela {idx + 1}: {table.row_count} linhas x {table.column_count} colunas\")\n",
    "                \n",
    "        # Extrair par√°grafos\n",
    "        if result.paragraphs:\n",
    "            print(f\"\\nPar√°grafos encontrados: {len(result.paragraphs)}\")\n",
    "            for idx, paragraph in enumerate(result.paragraphs[:3]):  # Mostrar apenas os 3 primeiros\n",
    "                print(f\"Par√°grafo {idx + 1}: {paragraph.content[:100]}...\")\n",
    "                \n",
    "        # Extrair pares chave-valor\n",
    "        if result.key_value_pairs:\n",
    "            print(f\"\\nPares chave-valor encontrados: {len(result.key_value_pairs)}\")\n",
    "            for kv_pair in result.key_value_pairs[:5]:  # Mostrar apenas os 5 primeiros\n",
    "                if kv_pair.key and kv_pair.value:\n",
    "                    print(f\"  {kv_pair.key.content}: {kv_pair.value.content}\")\n",
    "                    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Arquivo de documento n√£o encontrado: {doc_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no Document Intelligence: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Defina as vari√°veis DOC_INTELLIGENCE_ENDPOINT e DOC_INTELLIGENCE_KEY no arquivo .env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf190fab",
   "metadata": {},
   "source": [
    "### Exerc√≠cio 4 - Content Safety"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded113b8",
   "metadata": {},
   "source": [
    "A seguran√ßa de conte√∫do do Azure AI detecta conte√∫do prejudicial gerado por usu√°rios e por IA em aplicativos e servi√ßos. Este servi√ßo disponibiliza v√°rios tipos diferentes de an√°lise.\n",
    "\n",
    "**Escudos de Prompt** - Examina texto em busca de riscos de ataques de entrada do usu√°rio em um Modelo de Linguagem Grande.\n",
    "\n",
    "**Detec√ß√£o de fundamenta√ß√£o (preview)** - Detecta se as respostas de texto de modelos de linguagem grandes (LLMs) est√£o fundamentadas nos materiais fonte fornecidos pelos usu√°rios.\n",
    "\n",
    "**Detec√ß√£o de material protegido em texto** - Examina texto gerado por IA em busca de conte√∫do de texto conhecido (por exemplo, letras de m√∫sica, artigos, receitas, conte√∫do web selecionado).\n",
    "\n",
    "**API de categorias personalizadas (padr√£o) (preview)** - Permite criar e treinar suas pr√≥prias categorias de conte√∫do personalizadas e examinar texto em busca de correspond√™ncias.\n",
    "\n",
    "**API de categorias personalizadas (r√°pida) (preview)** - Permite definir padr√µes emergentes de conte√∫do prejudicial e examinar texto e imagens em busca de correspond√™ncias.\n",
    "\n",
    "**API de an√°lise de texto** - Examina texto em busca de conte√∫do sexual, viol√™ncia, √≥dio e autoles√£o com m√∫ltiplos n√≠veis de severidade.\n",
    "\n",
    "**API de an√°lise de imagem** - Examina imagens em busca de conte√∫do sexual, viol√™ncia, √≥dio e autoles√£o com m√∫ltiplos n√≠veis de severidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo - Content Safety (seguindo quickstart oficial)\n",
    "from azure.ai.contentsafety import ContentSafetyClient\n",
    "from azure.ai.contentsafety.models import AnalyzeTextOptions, TextCategory\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "def analyze_text_content(text_to_analyze):\n",
    "    \"\"\"\n",
    "    Fun√ß√£o para analisar texto usando Azure Content Safety\n",
    "    Baseada no quickstart oficial da Microsoft\n",
    "    \"\"\"\n",
    "    # Obter credenciais das vari√°veis de ambiente\n",
    "    key = os.getenv('CONTENT_SAFETY_KEY')\n",
    "    endpoint = os.getenv('CONTENT_SAFETY_ENDPOINT')\n",
    "    \n",
    "    if not key or not endpoint:\n",
    "        print(\"‚ùå Erro: Defina as vari√°veis CONTENT_SAFETY_KEY e CONTENT_SAFETY_ENDPOINT no arquivo .env\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Criar cliente Azure AI Content Safety\n",
    "        client = ContentSafetyClient(endpoint, AzureKeyCredential(key))\n",
    "        \n",
    "        # Configurar requisi√ß√£o\n",
    "        request = AnalyzeTextOptions(text=text_to_analyze)\n",
    "        \n",
    "        # Analisar texto\n",
    "        response = client.analyze_text(request)\n",
    "        \n",
    "        # Extrair resultados por categoria espec√≠fica (seguindo quickstart)\n",
    "        hate_result = next((item for item in response.categories_analysis if item.category == TextCategory.HATE), None)\n",
    "        self_harm_result = next((item for item in response.categories_analysis if item.category == TextCategory.SELF_HARM), None)\n",
    "        sexual_result = next((item for item in response.categories_analysis if item.category == TextCategory.SEXUAL), None)\n",
    "        violence_result = next((item for item in response.categories_analysis if item.category == TextCategory.VIOLENCE), None)\n",
    "        \n",
    "        # Exibir resultados\n",
    "        print(f\"üìù Texto analisado: '{text_to_analyze}'\")\n",
    "        print(\"üîç Resultados da an√°lise:\")\n",
    "        \n",
    "        if hate_result:\n",
    "            print(f\"  üí¨ √ìdio (Hate): Severidade {hate_result.severity}\")\n",
    "        if self_harm_result:\n",
    "            print(f\"  ü©π Autoles√£o (Self-harm): Severidade {self_harm_result.severity}\")\n",
    "        if sexual_result:\n",
    "            print(f\"  üîû Sexual: Severidade {sexual_result.severity}\")\n",
    "        if violence_result:\n",
    "            print(f\"  ‚öîÔ∏è  Viol√™ncia (Violence): Severidade {violence_result.severity}\")\n",
    "        \n",
    "        # Interpretar n√≠vel de risco geral\n",
    "        max_severity = max([\n",
    "            hate_result.severity if hate_result else 0,\n",
    "            self_harm_result.severity if self_harm_result else 0,\n",
    "            sexual_result.severity if sexual_result else 0,\n",
    "            violence_result.severity if violence_result else 0\n",
    "        ])\n",
    "        \n",
    "        if max_severity == 0:\n",
    "            risk_level = \"‚úÖ Seguro\"\n",
    "        elif max_severity <= 2:\n",
    "            risk_level = \"‚ö†Ô∏è Baixo risco\"\n",
    "        elif max_severity <= 4:\n",
    "            risk_level = \"üî∏ Risco moderado\"\n",
    "        else:\n",
    "            risk_level = \"üî¥ Alto risco\"\n",
    "            \n",
    "        print(f\"üìä Avalia√ß√£o geral: {risk_level}\")\n",
    "        return response\n",
    "        \n",
    "    except HttpResponseError as e:\n",
    "        print(\"‚ùå Falha na an√°lise de texto.\")\n",
    "        if e.error:\n",
    "            print(f\"C√≥digo do erro: {e.error.code}\")\n",
    "            print(f\"Mensagem do erro: {e.error.message}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro inesperado: {e}\")\n",
    "        return None\n",
    "\n",
    "# Configurar cliente Content Safety\n",
    "content_safety_endpoint = os.getenv('CONTENT_SAFETY_ENDPOINT')\n",
    "content_safety_key = os.getenv('CONTENT_SAFETY_KEY')\n",
    "\n",
    "if content_safety_endpoint and content_safety_key:\n",
    "    print(\"=== Content Safety - An√°lise de Texto ===\")\n",
    "    print(\"Baseado no quickstart oficial da Microsoft\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Textos de exemplo para an√°lise (incluindo diferentes n√≠veis de risco)\n",
    "    test_texts = [\n",
    "        \"Ol√°! Como voc√™ est√° hoje? Tenha um √≥timo dia!\",\n",
    "        \"Este √© um texto neutro sobre tecnologia e programa√ß√£o em Python.\",\n",
    "        \"Estou muito bravo com esta situa√ß√£o, mas vou resolver de forma civilizada.\",\n",
    "        \"Texto de teste para modera√ß√£o de conte√∫do potencialmente problem√°tico.\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"üìã Analisando {len(test_texts)} textos de exemplo...\\n\")\n",
    "    \n",
    "    for idx, text in enumerate(test_texts, 1):\n",
    "        print(f\"üîç An√°lise {idx}/{len(test_texts)}:\")\n",
    "        result = analyze_text_content(text)\n",
    "        \n",
    "        if result:\n",
    "            print(\"‚úÖ An√°lise conclu√≠da com sucesso\")\n",
    "        else:\n",
    "            print(\"‚ùå Falha na an√°lise\")\n",
    "            \n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Configura√ß√£o necess√°ria:\")\n",
    "    print(\"Defina as vari√°veis CONTENT_SAFETY_ENDPOINT e CONTENT_SAFETY_KEY no arquivo .env\")\n",
    "    print(\"\\nExemplo de configura√ß√£o:\")\n",
    "    print(\"CONTENT_SAFETY_ENDPOINT=https://your-content-safety.cognitiveservices.azure.com/\")\n",
    "    print(\"CONTENT_SAFETY_KEY=your-content-safety-key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b195fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo - Content Safety para Imagens (seguindo quickstart oficial)\n",
    "from azure.ai.contentsafety.models import AnalyzeImageOptions, ImageData\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "def analyze_image_content(image_path):\n",
    "    \"\"\"\n",
    "    Fun√ß√£o para analisar imagem usando Azure Content Safety\n",
    "    Baseada no quickstart oficial da Microsoft\n",
    "    \"\"\"\n",
    "    # Obter credenciais das vari√°veis de ambiente\n",
    "    key = os.getenv('CONTENT_SAFETY_KEY')\n",
    "    endpoint = os.getenv('CONTENT_SAFETY_ENDPOINT')\n",
    "    \n",
    "    if not key or not endpoint:\n",
    "        print(\"‚ùå Erro: Defina as vari√°veis CONTENT_SAFETY_KEY e CONTENT_SAFETY_ENDPOINT no arquivo .env\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Criar cliente Azure AI Content Safety\n",
    "        client = ContentSafetyClient(endpoint, AzureKeyCredential(key))\n",
    "        \n",
    "        # Ler imagem\n",
    "        with open(image_path, \"rb\") as file:\n",
    "            image_data = file.read()\n",
    "            \n",
    "        # Configurar requisi√ß√£o para an√°lise de imagem\n",
    "        request = AnalyzeImageOptions(image=ImageData(content=image_data))\n",
    "        \n",
    "        # Analisar imagem\n",
    "        response = client.analyze_image(request)\n",
    "        \n",
    "        # Extrair resultados por categoria espec√≠fica\n",
    "        hate_result = next((item for item in response.categories_analysis if item.category == TextCategory.HATE), None)\n",
    "        self_harm_result = next((item for item in response.categories_analysis if item.category == TextCategory.SELF_HARM), None)\n",
    "        sexual_result = next((item for item in response.categories_analysis if item.category == TextCategory.SEXUAL), None)\n",
    "        violence_result = next((item for item in response.categories_analysis if item.category == TextCategory.VIOLENCE), None)\n",
    "        \n",
    "        # Exibir resultados\n",
    "        print(f\"üñºÔ∏è Imagem analisada: {image_path}\")\n",
    "        print(\"üîç Resultados da an√°lise:\")\n",
    "        \n",
    "        if hate_result:\n",
    "            print(f\"  üí¨ √ìdio (Hate): Severidade {hate_result.severity}\")\n",
    "        if self_harm_result:\n",
    "            print(f\"  ü©π Autoles√£o (Self-harm): Severidade {self_harm_result.severity}\")\n",
    "        if sexual_result:\n",
    "            print(f\"  üîû Sexual: Severidade {sexual_result.severity}\")\n",
    "        if violence_result:\n",
    "            print(f\"  ‚öîÔ∏è  Viol√™ncia (Violence): Severidade {violence_result.severity}\")\n",
    "        \n",
    "        # Interpretar n√≠vel de risco geral\n",
    "        max_severity = max([\n",
    "            hate_result.severity if hate_result else 0,\n",
    "            self_harm_result.severity if self_harm_result else 0,\n",
    "            sexual_result.severity if sexual_result else 0,\n",
    "            violence_result.severity if violence_result else 0\n",
    "        ])\n",
    "        \n",
    "        if max_severity == 0:\n",
    "            risk_level = \"‚úÖ Seguro\"\n",
    "        elif max_severity <= 2:\n",
    "            risk_level = \"‚ö†Ô∏è Baixo risco\"\n",
    "        elif max_severity <= 4:\n",
    "            risk_level = \"üî∏ Risco moderado\"\n",
    "        else:\n",
    "            risk_level = \"üî¥ Alto risco\"\n",
    "            \n",
    "        print(f\"üìä Avalia√ß√£o geral: {risk_level}\")\n",
    "        return response\n",
    "        \n",
    "    except HttpResponseError as e:\n",
    "        print(\"‚ùå Falha na an√°lise de imagem.\")\n",
    "        if e.error:\n",
    "            print(f\"C√≥digo do erro: {e.error.code}\")\n",
    "            print(f\"Mensagem do erro: {e.error.message}\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Erro: Arquivo de imagem n√£o encontrado: {image_path}\")\n",
    "        print(\"Verifique se o caminho da imagem est√° correto.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro inesperado: {e}\")\n",
    "        return None\n",
    "\n",
    "if content_safety_endpoint and content_safety_key:\n",
    "    print(\"\\n=== Content Safety - An√°lise de Imagem ===\")\n",
    "    print(\"Baseado no quickstart oficial da Microsoft\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Caminhos para imagens de exemplo\n",
    "    image_paths = [\n",
    "        \"../../../samples/234039841.jpg\",\n",
    "        \"../../../samples/car-accident.png\"\n",
    "    ]\n",
    "    \n",
    "    for idx, image_path in enumerate(image_paths, 1):\n",
    "        print(f\"\\nüîç An√°lise {idx}/{len(image_paths)}:\")\n",
    "        result = analyze_image_content(image_path)\n",
    "        \n",
    "        if result:\n",
    "            print(\"‚úÖ An√°lise conclu√≠da com sucesso\")\n",
    "        else:\n",
    "            print(\"‚ùå Falha na an√°lise\")\n",
    "            \n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Configura√ß√£o necess√°ria:\")\n",
    "    print(\"Defina as vari√°veis CONTENT_SAFETY_ENDPOINT e CONTENT_SAFETY_KEY no arquivo .env\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

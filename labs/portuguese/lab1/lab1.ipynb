{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b30b8379",
   "metadata": {},
   "source": [
    "# Azure AI Foundry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abd7c63",
   "metadata": {},
   "source": [
    "<center><img src=\"../../../images/Azure-AI-Foundry_1600x900.jpg\" alt=\"Azure AI Foundry\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2920c647",
   "metadata": {},
   "source": [
    "## LaboratÃ³rio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81dc1f9",
   "metadata": {},
   "source": [
    "Neste laboratÃ³rio iremos realizar a conexÃ£o com o Azure OpenAI e executar diversas tarefas: solicitar respostas da API, usar respostas baseadas em texto, analisar as respostas obtidas, realizar a conversÃ£o de texto em embeddings, fazer chamadas Ã  API enviando imagens e tambÃ©m realizar chamadas a outros modelos LLM.\n",
    "\n",
    "O primeiro passo Ã© a validaÃ§Ã£o da configuraÃ§Ã£o das variÃ¡veis de ambiente no arquivo `.env` presente na raiz do repositÃ³rio.\n",
    "\n",
    "Preencha os valores das variÃ¡veis de acordo com o solicitado.\n",
    "\n",
    "### ExercÃ­cio 1 - Chamada Ã  API\n",
    "\n",
    "Vamos realizar a importaÃ§Ã£o das bibliotecas necessÃ¡rias para o laboratÃ³rio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eed29d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c067a964",
   "metadata": {},
   "source": [
    "Vamos carregar as credenciais em variÃ¡veis para facilitar o uso no laboratÃ³rio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a2059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "api_version=os.getenv(\"API_VERSION\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec7e921",
   "metadata": {},
   "source": [
    "Agora vamos iniciar o client com as credenciais fornecidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561e832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "  azure_endpoint = azure_endpoint[0], \n",
    "  api_key=api_key[0],  \n",
    "  api_version=api_version\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509b0493",
   "metadata": {},
   "source": [
    "ApÃ³s criarmos o cliente, vamos realizar uma chamada simples onde passaremos:\n",
    "\n",
    "1. Uma mensagem para a role \"system\" definindo o papel da LLM\n",
    "2. Uma pergunta inicial do usuÃ¡rio\n",
    "3. Uma resposta do assistente demonstrando como ele deve responder (exemplo)\n",
    "4. Uma nova pergunta para ele responder baseado no contexto estabelecido anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647af5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=deployment_name, \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"VocÃª Ã© um assistente Ãºtil.\"},\n",
    "        {\"role\": \"user\", \"content\": \"O Azure OpenAI suporta chaves gerenciadas pelo cliente?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Sim, chaves gerenciadas pelo cliente sÃ£o suportadas pelo Azure OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Outros serviÃ§os do Azure tambÃ©m suportam isso?\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91875481",
   "metadata": {},
   "source": [
    "Agora vamos acessar diretamente a resposta da LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d19bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c4a22a",
   "metadata": {},
   "source": [
    "### ExercÃ­cio 2 - Analisando a Resposta\n",
    "\n",
    "Agora que fizemos uma chamada para o Azure OpenAI, vamos analisar o conteÃºdo completo da resposta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da23911",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8718d0a3",
   "metadata": {},
   "source": [
    "Agora vamos estruturar a resposta em um formato mais legÃ­vel para melhor visualizaÃ§Ã£o dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf8cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict = {\n",
    "    \"id\": response.id,\n",
    "    \"model\": response.model,\n",
    "    \"created\": response.created,\n",
    "    \"usage\": {\n",
    "        \"prompt_tokens\": response.usage.prompt_tokens,\n",
    "        \"completion_tokens\": response.usage.completion_tokens,\n",
    "        \"total_tokens\": response.usage.total_tokens\n",
    "    },\n",
    "    \"completion_tokens_details\": {\n",
    "        \"accepted_prediction_tokens\": response.usage.completion_tokens_details.accepted_prediction_tokens,\n",
    "        \"audio_tokens\": response.usage.completion_tokens_details.audio_tokens,\n",
    "        \"reasoning_tokens\": response.usage.completion_tokens_details.reasoning_tokens,\n",
    "        \"rejected_prediction_tokens\": response.usage.completion_tokens_details.rejected_prediction_tokens\n",
    "    },\n",
    "    \"choices\": [{\n",
    "        \"index\": choice.index,\n",
    "        \"message\": {\n",
    "            \"role\": choice.message.role,\n",
    "            \"content\": choice.message.content\n",
    "        },\n",
    "        \"finish_reason\": choice.finish_reason,\n",
    "        \"content_filter_results\": choice.content_filter_results\n",
    "    } for choice in response.choices],\n",
    "    \"prompt_filter_results\": response.prompt_filter_results\n",
    "}\n",
    "\n",
    "print(json.dumps(response_dict, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3502f5f9",
   "metadata": {},
   "source": [
    "A API nÃ£o responde apenas com o texto gerado pela LLM. Temos muito mais informaÃ§Ãµes nessa resposta, como por exemplo:\n",
    "- Se usa Ã¡udio ou imagem\n",
    "- Filtragem de conteÃºdo\n",
    "- AvaliaÃ§Ã£o de conteÃºdo\n",
    "- Contagem de tokens do prompt\n",
    "- Contagem de tokens gerados na resposta\n",
    "- Detalhes sobre tokens de raciocÃ­nio (para modelos que suportam)\n",
    "- Resultados de filtros aplicados\n",
    "\n",
    "Essas informaÃ§Ãµes sÃ£o essenciais para monitoramento, custos e controle de qualidade da aplicaÃ§Ã£o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e30d33",
   "metadata": {},
   "source": [
    "ApÃ³s realizar a chamada e explorar a resposta, teste vocÃª tambÃ©m criando um prompt personalizado. Realize experimentos com os seguintes parÃ¢metros importantes:\n",
    "\n",
    "- **max_completion_tokens**: NÃºmero mÃ¡ximo de tokens que podem ser gerados na resposta\n",
    "- **temperature**: Controla a criatividade (0.0 = mais determinÃ­stico, 1.0 = mais criativo)\n",
    "- **top_p**: Controla a diversidade da resposta via nucleus sampling\n",
    "- **frequency_penalty**: Penaliza repetiÃ§Ã£o de tokens baseado na frequÃªncia\n",
    "- **presence_penalty**: Penaliza repetiÃ§Ã£o de tokens independentemente da frequÃªncia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0315241",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"VocÃª Ã© um assistente Ãºtil.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Vou viajar para Paris, o que devo ver?\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Paris, a capital da FranÃ§a, Ã© conhecida por sua arquitetura deslumbrante, museus de arte, marcos histÃ³ricos e atmosfera romÃ¢ntica. Aqui estÃ£o algumas das principais atraÃ§Ãµes para ver em Paris:\\n \\n 1. A Torre Eiffel: A icÃ´nica Torre Eiffel Ã© um dos marcos mais reconhecÃ­veis do mundo e oferece vistas deslumbrantes da cidade.\\n 2. O Museu do Louvre: O Louvre Ã© um dos maiores e mais famosos museus do mundo, abrigando uma impressionante coleÃ§Ã£o de arte e artefatos, incluindo a Mona Lisa.\\n 3. Catedral de Notre-Dame: Esta bela catedral Ã© um dos marcos mais famosos de Paris e Ã© conhecida por sua arquitetura gÃ³tica e vitrais deslumbrantes.\\n \\n Estas sÃ£o apenas algumas das muitas atraÃ§Ãµes que Paris tem a oferecer. Com tanto para ver e fazer, nÃ£o Ã© de admirar que Paris seja um dos destinos turÃ­sticos mais populares do mundo.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"O que hÃ¡ de tÃ£o especial no #1?\",\n",
    "        }\n",
    "    ],\n",
    "    max_completion_tokens=800,\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0,\n",
    "    model=deployment_name\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da921c2e",
   "metadata": {},
   "source": [
    "### ExercÃ­cio 3 - Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27f7ec3",
   "metadata": {},
   "source": [
    "Os embeddings sÃ£o representaÃ§Ãµes numÃ©ricas de texto que capturam o significado semÃ¢ntico das palavras ou frases. No Azure OpenAI, vocÃª pode usar o modelo de embeddings para converter texto em vetores numÃ©ricos que podem ser usados para tarefas como busca semÃ¢ntica, classificaÃ§Ã£o e anÃ¡lise de similaridade.\n",
    "\n",
    "Para mais informaÃ§Ãµes sobre como trabalhar com embeddings no Azure OpenAI, consulte a [documentaÃ§Ã£o oficial](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/embeddings?tabs=python-new)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd62c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.embeddings.create(\n",
    "    input = \"cachorro\",\n",
    "    model= embedding_model\n",
    ")\n",
    "\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeb31ca",
   "metadata": {},
   "source": [
    "Aqui geramos o embedding de uma Ãºnica palavra, mas podemos fazer o mesmo para trechos de texto maiores. O modelo organizarÃ¡ automaticamente o conteÃºdo em vetores numÃ©ricos que capturam o significado semÃ¢ntico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd249d1c",
   "metadata": {},
   "source": [
    "Para armazenar embeddings podemos usar uma sÃ©rie de serviÃ§os disponÃ­veis no Azure. Basta escolher o que mais se adequa Ã  sua soluÃ§Ã£o:\n",
    "\n",
    "- [Azure AI Search](https://learn.microsoft.com/en-us/azure/search/vector-search-overview)\n",
    "- [Azure Cosmos DB for MongoDB vCore](https://learn.microsoft.com/en-us/azure/cosmos-db/mongodb/vcore/vector-search)\n",
    "- [Azure SQL Database](https://learn.microsoft.com/en-us/azure/azure-sql/database/ai-artificial-intelligence-intelligent-applications?view=azuresql&preserve-view=true#vector-search)\n",
    "- [Azure Cosmos DB for NoSQL](https://learn.microsoft.com/en-us/azure/cosmos-db/vector-search)\n",
    "- [Azure Cosmos DB for PostgreSQL](https://learn.microsoft.com/en-us/azure/cosmos-db/postgresql/howto-use-pgvector)\n",
    "- [Azure Database for PostgreSQL - Flexible Server](https://learn.microsoft.com/en-us/azure/postgresql/flexible-server/how-to-use-pgvector)\n",
    "- [Azure Cache for Redis](https://learn.microsoft.com/en-us/azure/azure-cache-for-redis/cache-tutorial-vector-similarity)\n",
    "- [Use Eventhouse as a vector database - Real-Time Intelligence in Microsoft Fabric](https://learn.microsoft.com/en-us/fabric/real-time-intelligence/vector-database)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447d5fa7",
   "metadata": {},
   "source": [
    "### ExercÃ­cio 4 - Processamento de Imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0534223",
   "metadata": {},
   "source": [
    "No Azure AI Foundry podemos trabalhar com modelos que processam imagens, tanto para geraÃ§Ã£o de imagens quanto modelos multimodais nos quais podemos usar imagens como contexto. Neste exercÃ­cio vamos aprender como utilizar imagens como contexto do prompt.\n",
    "\n",
    "**Primeiro ponto importante**: temos que pensar em como enviar uma imagem junto ao prompt. Para isso temos 2 opÃ§Ãµes principais:\n",
    "1. Enviar a imagem junto com o prompt via base64 (codificada)\n",
    "2. Enviar a imagem como um link/URL\n",
    "\n",
    "Vamos ver os 2 exemplos prÃ¡ticos a seguir.\n",
    "\n",
    "Primeiro, vamos aproveitar o cliente que jÃ¡ instanciamos e enviar uma URL de uma imagem, pedindo para o modelo descrevÃª-la:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e0f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Itaim_Bibi_Business_District.jpg/250px-Itaim_Bibi_Business_District.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f371ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        { \"role\": \"system\", \"content\": \"VocÃª Ã© um assistente Ãºtil.\" },\n",
    "        { \"role\": \"user\", \"content\": [  \n",
    "            { \n",
    "                \"type\": \"text\", \n",
    "                \"text\": \"Descreva essa imagem:\" \n",
    "            },\n",
    "            { \n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": image_url\n",
    "                }\n",
    "            }\n",
    "        ] } \n",
    "    ],\n",
    "    max_tokens=2000 \n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20495db6",
   "metadata": {},
   "source": [
    "Agora vamos ler uma imagem local armazenada em nosso sistema e enviÃ¡-la junto com a mensagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb92d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from mimetypes import guess_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e59d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_image_to_data_url(image_path):\n",
    "    # Guess the MIME type of the image based on the file extension\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = 'application/octet-stream'  # Default MIME type if none is found\n",
    "\n",
    "    # Read and encode the image file\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # Construct the data URL\n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b95c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"../../../samples/234039841.jpg\"\n",
    "data_url = local_image_to_data_url(image_path)\n",
    "print(\"Data URL:\", data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7209a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        { \"role\": \"system\", \"content\": \"VocÃª Ã© um assistente Ãºtil.\" },\n",
    "        { \"role\": \"user\", \"content\": [  \n",
    "            { \n",
    "                \"type\": \"text\", \n",
    "                \"text\": \"Descreva essa imagem:\" \n",
    "            },\n",
    "            { \n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": data_url\n",
    "                }\n",
    "            }\n",
    "        ] } \n",
    "    ],\n",
    "    max_tokens=2000 \n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eb4452",
   "metadata": {},
   "source": [
    "Utilizando o Azure OpenAI temos acesso a diversos tipos de funcionalidades alÃ©m das que exploramos aqui. Recomendo navegar e explorar as opÃ§Ãµes disponÃ­veis para entender qual Ã© a melhor abordagem para sua aplicaÃ§Ã£o especÃ­fica:\n",
    "\n",
    "- [Responses API](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/responses)\n",
    "- [Reasoning Models](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/reasoning)\n",
    "- [Chat completions API](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/chatgpt)\n",
    "- [Computer Use](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/computer-use)\n",
    "- [Model router concepts](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/model-router)\n",
    "- [Function calling](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/function-calling)\n",
    "- [Predicted outputs](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/predicted-outputs)\n",
    "- [Prompt caching](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/prompt-caching)\n",
    "- [Structured outputs](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/structured-outputs)\n",
    "- [Vision-enabled chats](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/structured-outputs)\n",
    "- [JSON Mode](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/json-mode)\n",
    "- [Reproducible output](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/reproducible-output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e339935",
   "metadata": {},
   "source": [
    "### ExercÃ­cio 5 - Outros modelos no Azure AI Foundry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841d9392",
   "metadata": {},
   "source": [
    "AtravÃ©s do Azure AI Foundry podemos explorar uma sÃ©rie de modelos disponÃ­veis no [Model Catalog](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/foundry-models-overview). \n",
    "\n",
    "LÃ¡ temos acesso a modelos que sÃ£o disponibilizados pela Microsoft (OpenAI, Meta, Mistral AI, Deepseek, xAI, Black Forest Labs) bem como modelos disponibilizados por parceiros e pela comunidade (Nixtla, AI21, NTT Data, Core42, NVIDIA NIM Microservices, Stability AI). \n",
    "\n",
    "AtravÃ©s da documentaÃ§Ã£o fornecida Ã© possÃ­vel entender a diferenÃ§a entre os diferentes modos de disponibilizaÃ§Ã£o dos modelos e como escolher de acordo com seu cenÃ¡rio especÃ­fico.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69a06ee",
   "metadata": {},
   "source": [
    "Agora vamos seguir com um exemplo prÃ¡tico de como chamar um modelo disponibilizado pelo Azure AI Foundry atravÃ©s de uma chamada de chat completion usando uma biblioteca diferente da anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e12962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e70958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = os.getenv(\"AZURE_PHI4_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_PHI4_API_KEY\")\n",
    "model_name = os.getenv(\"AZURE_PHI4_DEPLOYMENT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d21217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clientPhi = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(api_key),\n",
    "    api_version=os.getenv(\"AZURE_PHI4_API_VERSION\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694aa690",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = clientPhi.complete(\n",
    "    messages=[\n",
    "        SystemMessage(content=\"VocÃª Ã© um assistente Ãºtil.\"),\n",
    "        UserMessage(content=\"Vou viajar para Paris, o que devo ver?\"),\n",
    "    ],\n",
    "    max_tokens=2048,\n",
    "    temperature=0.8,\n",
    "    top_p=0.1,\n",
    "    presence_penalty=0.0,\n",
    "    frequency_penalty=0.0,\n",
    "    model=model_name\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7941d5",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Atividades PrÃ¡ticas \n",
    "\n",
    "Agora que vocÃª explorou os conceitos bÃ¡sicos do Azure AI Foundry, vamos praticar com algumas atividades simples e direcionadas para consolidar o aprendizado!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d5ad2",
   "metadata": {},
   "source": [
    "### ðŸ“ Atividade 1: Teste de Temperatura\n",
    "**Objetivo**: Entender como a temperatura afeta a criatividade das respostas.\n",
    "\n",
    "Execute o cÃ³digo abaixo e observe como o mesmo prompt gera respostas diferentes com temperaturas variadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a292ffab",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Escreva um slogan criativo para uma empresa de tecnologia.\"\n",
    "\n",
    "# Testando diferentes temperaturas\n",
    "temperaturas = [0.1, 0.5, 1.0]\n",
    "\n",
    "for temp in temperaturas:\n",
    "    print(f\"\\nðŸŒ¡ï¸ TEMPERATURA: {temp}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"VocÃª Ã© um assistente criativo de marketing.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temp,\n",
    "        max_completion_tokens=100\n",
    "    )\n",
    "    \n",
    "    print(response.choices[0].message.content)\n",
    "    print(f\"Tokens usados: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbf57e0",
   "metadata": {},
   "source": [
    "### ðŸ” Atividade 2: ComparaÃ§Ã£o de Embeddings\n",
    "**Objetivo**: Comparar como palavras similares tÃªm embeddings prÃ³ximos.\n",
    "\n",
    "Vamos gerar embeddings para palavras relacionadas e ver seus tamanhos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001ffdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Palavras para comparar\n",
    "palavras = [\"gato\", \"felino\", \"cachorro\", \"cÃ£o\", \"automÃ³vel\", \"carro\"]\n",
    "\n",
    "embeddings_dict = {}\n",
    "\n",
    "print(\"Gerando embeddings para as palavras...\")\n",
    "for palavra in palavras:\n",
    "    response = client.embeddings.create(\n",
    "        input=palavra,\n",
    "        model=embedding_model\n",
    "    )\n",
    "    embedding = response.data[0].embedding\n",
    "    embeddings_dict[palavra] = embedding\n",
    "    print(f\"âœ… {palavra}: {len(embedding)} dimensÃµes\")\n",
    "\n",
    "print(f\"\\nPrimeiros 5 valores do embedding da palavra 'gato':\")\n",
    "print(embeddings_dict[\"gato\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb7939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FunÃ§Ã£o para calcular similaridade de cosseno\n",
    "def calcular_similaridade(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Comparando similaridades\n",
    "print(\"ðŸ” Comparando similaridades:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Gato vs Felino\n",
    "sim_gato_felino = calcular_similaridade(embeddings_dict[\"gato\"], embeddings_dict[\"felino\"])\n",
    "print(f\"Gato â†” Felino: {sim_gato_felino:.3f}\")\n",
    "\n",
    "# Cachorro vs CÃ£o\n",
    "sim_cachorro_cao = calcular_similaridade(embeddings_dict[\"cachorro\"], embeddings_dict[\"cÃ£o\"])\n",
    "print(f\"Cachorro â†” CÃ£o: {sim_cachorro_cao:.3f}\")\n",
    "\n",
    "# AutomÃ³vel vs Carro\n",
    "sim_auto_carro = calcular_similaridade(embeddings_dict[\"automÃ³vel\"], embeddings_dict[\"carro\"])\n",
    "print(f\"AutomÃ³vel â†” Carro: {sim_auto_carro:.3f}\")\n",
    "\n",
    "# Gato vs Carro (deve ser baixa)\n",
    "sim_gato_carro = calcular_similaridade(embeddings_dict[\"gato\"], embeddings_dict[\"carro\"])\n",
    "print(f\"Gato â†” Carro: {sim_gato_carro:.3f}\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ Palavras similares tÃªm similaridade mais alta (prÃ³xima de 1.0)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de733df",
   "metadata": {},
   "source": [
    "### ðŸ–¼ï¸ Atividade 3: AnÃ¡lise de Imagem com Diferentes Prompts\n",
    "**Objetivo**: Testar como diferentes prompts afetam a anÃ¡lise da mesma imagem.\n",
    "\n",
    "Vamos usar diferentes tipos de perguntas para a mesma imagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa305916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando a mesma imagem com diferentes prompts\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Itaim_Bibi_Business_District.jpg/250px-Itaim_Bibi_Business_District.jpg\"\n",
    "\n",
    "# Diferentes tipos de anÃ¡lise\n",
    "prompts = [\n",
    "    \"Descreva esta imagem em uma frase:\",\n",
    "    \"Que tipo de local Ã© este?\",\n",
    "    \"Quais cores predominam nesta imagem?\",\n",
    "    \"Esta imagem transmite que sensaÃ§Ã£o?\",\n",
    "    \"Conte os prÃ©dios que vocÃª consegue ver:\"\n",
    "]\n",
    "\n",
    "for i, prompt_text in enumerate(prompts, 1):\n",
    "    print(f\"\\nðŸ” PERGUNTA {i}: {prompt_text}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"VocÃª Ã© um assistente especializado em anÃ¡lise de imagens.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt_text},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "            ]}\n",
    "        ],\n",
    "        max_tokens=150\n",
    "    )\n",
    "    \n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b6d8ae",
   "metadata": {},
   "source": [
    "### ðŸ”¢ Atividade 4: Contador de Tokens\n",
    "**Objetivo**: Entender como o tamanho do prompt afeta o consumo de tokens.\n",
    "\n",
    "Vamos testar prompts de diferentes tamanhos e ver o impacto nos tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ba7972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts de diferentes tamanhos\n",
    "prompts_teste = [\n",
    "    \"OlÃ¡\",\n",
    "    \"Explique o que Ã© inteligÃªncia artificial\",\n",
    "    \"Explique detalhadamente o que Ã© inteligÃªncia artificial, como funciona, suas aplicaÃ§Ãµes prÃ¡ticas, benefÃ­cios e desafios para a sociedade moderna\"\n",
    "]\n",
    "\n",
    "print(\"ðŸ“Š ANÃLISE DE CONSUMO DE TOKENS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, prompt in enumerate(prompts_teste, 1):\n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"VocÃª Ã© um assistente Ãºtil.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_completion_tokens=100  # Limitando resposta para focar no prompt\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nðŸ” TESTE {i}:\")\n",
    "    print(f\"Prompt: '{prompt[:50]}{'...' if len(prompt) > 50 else ''}'\")\n",
    "    print(f\"Tokens do prompt: {response.usage.prompt_tokens}\")\n",
    "    print(f\"Tokens da resposta: {response.usage.completion_tokens}\")\n",
    "    print(f\"Total de tokens: {response.usage.total_tokens}\")\n",
    "    print(f\"Resposta: {response.choices[0].message.content[:100]}...\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Prompts maiores consomem mais tokens de entrada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1351a490",
   "metadata": {},
   "source": [
    "### ðŸŽ­ Atividade 5: Teste de Personas\n",
    "**Objetivo**: Ver como diferentes personas (system messages) afetam as respostas.\n",
    "\n",
    "Vamos fazer a mesma pergunta para diferentes \"personalidades\" do assistente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3efb557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diferentes personas para testar\n",
    "personas = [\n",
    "    {\"nome\": \"Professor\", \"system\": \"VocÃª Ã© um professor universitÃ¡rio que explica conceitos de forma didÃ¡tica e detalhada.\"},\n",
    "    {\"nome\": \"Amigo\", \"system\": \"VocÃª Ã© um amigo prÃ³ximo que conversa de forma casual e descontraÃ­da.\"},\n",
    "    {\"nome\": \"Especialista\", \"system\": \"VocÃª Ã© um especialista tÃ©cnico que dÃ¡ respostas precisas e diretas.\"},\n",
    "    {\"nome\": \"Poeta\", \"system\": \"VocÃª Ã© um poeta que responde sempre de forma criativa e artÃ­stica.\"}\n",
    "]\n",
    "\n",
    "pergunta = \"O que vocÃª pensa sobre o futuro da tecnologia?\"\n",
    "\n",
    "print(\"ðŸŽ­ TESTANDO DIFERENTES PERSONAS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for persona in personas:\n",
    "    print(f\"\\nðŸ‘¤ PERSONA: {persona['nome']}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": persona[\"system\"]},\n",
    "            {\"role\": \"user\", \"content\": pergunta}\n",
    "        ],\n",
    "        max_completion_tokens=200,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "print(\"\\nðŸ’¡ O system message define completamente o 'jeito' do assistente!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

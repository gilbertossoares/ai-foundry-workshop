{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b30b8379",
   "metadata": {},
   "source": [
    "# Azure AI Foundry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abd7c63",
   "metadata": {},
   "source": [
    "<center><img src=\"../../../images/Azure-AI-Foundry_1600x900.jpg\" alt=\"Azure AI Foundry\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2920c647",
   "metadata": {},
   "source": [
    "## Laborat√≥rio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81dc1f9",
   "metadata": {},
   "source": [
    "Neste laborat√≥rio iremos realizar a conex√£o com o Azure OpenAI e executar diversas tarefas: solicitar respostas da API, usar respostas baseadas em texto, analisar as respostas obtidas, realizar a convers√£o de texto em embeddings, fazer chamadas √† API enviando imagens e tamb√©m realizar chamadas a outros modelos LLM.\n",
    "\n",
    "O primeiro passo √© a valida√ß√£o da configura√ß√£o das vari√°veis de ambiente no arquivo `.env` presente na raiz do reposit√≥rio.\n",
    "\n",
    "Preencha os valores das vari√°veis de acordo com o solicitado.\n",
    "\n",
    "### Exerc√≠cio 1 - Chamada √† API\n",
    "\n",
    "Vamos realizar a importa√ß√£o das bibliotecas necess√°rias para o laborat√≥rio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc9d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f06361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install openai dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eed29d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../../../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c067a964",
   "metadata": {},
   "source": [
    "Vamos carregar as credenciais em vari√°veis para facilitar o uso no laborat√≥rio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a2059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "api_version=os.getenv(\"API_VERSION\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec7e921",
   "metadata": {},
   "source": [
    "Agora vamos iniciar o client com as credenciais fornecidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561e832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "  azure_endpoint = azure_endpoint[0], \n",
    "  api_key=api_key[0],  \n",
    "  api_version=api_version\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509b0493",
   "metadata": {},
   "source": [
    "Ap√≥s criarmos o cliente, vamos realizar uma chamada simples onde passaremos:\n",
    "\n",
    "1. Uma mensagem para a role \"system\" definindo o papel da LLM\n",
    "2. Uma pergunta inicial do usu√°rio\n",
    "3. Uma resposta do assistente demonstrando como ele deve responder (exemplo)\n",
    "4. Uma nova pergunta para ele responder baseado no contexto estabelecido anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647af5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=deployment_name, \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Voc√™ √© um assistente √∫til.\"},\n",
    "        {\"role\": \"user\", \"content\": \"O Azure OpenAI suporta chaves gerenciadas pelo cliente?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Sim, chaves gerenciadas pelo cliente s√£o suportadas pelo Azure OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Outros servi√ßos do Azure tamb√©m suportam isso?\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91875481",
   "metadata": {},
   "source": [
    "Agora vamos acessar diretamente a resposta da LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d19bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c4a22a",
   "metadata": {},
   "source": [
    "### Exerc√≠cio 2 - Analisando a Resposta\n",
    "\n",
    "Agora que fizemos uma chamada para o Azure OpenAI, vamos analisar o conte√∫do completo da resposta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da23911",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8718d0a3",
   "metadata": {},
   "source": [
    "Agora vamos estruturar a resposta em um formato mais leg√≠vel para melhor visualiza√ß√£o dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf8cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict = {\n",
    "    \"id\": response.id,\n",
    "    \"model\": response.model,\n",
    "    \"created\": response.created,\n",
    "    \"usage\": {\n",
    "        \"prompt_tokens\": response.usage.prompt_tokens,\n",
    "        \"completion_tokens\": response.usage.completion_tokens,\n",
    "        \"total_tokens\": response.usage.total_tokens\n",
    "    },\n",
    "    \"completion_tokens_details\": {\n",
    "        \"accepted_prediction_tokens\": response.usage.completion_tokens_details.accepted_prediction_tokens,\n",
    "        \"audio_tokens\": response.usage.completion_tokens_details.audio_tokens,\n",
    "        \"reasoning_tokens\": response.usage.completion_tokens_details.reasoning_tokens,\n",
    "        \"rejected_prediction_tokens\": response.usage.completion_tokens_details.rejected_prediction_tokens\n",
    "    },\n",
    "    \"choices\": [{\n",
    "        \"index\": choice.index,\n",
    "        \"message\": {\n",
    "            \"role\": choice.message.role,\n",
    "            \"content\": choice.message.content\n",
    "        },\n",
    "        \"finish_reason\": choice.finish_reason,\n",
    "        \"content_filter_results\": choice.content_filter_results\n",
    "    } for choice in response.choices],\n",
    "    \"prompt_filter_results\": response.prompt_filter_results\n",
    "}\n",
    "\n",
    "print(json.dumps(response_dict, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3502f5f9",
   "metadata": {},
   "source": [
    "A API n√£o responde apenas com o texto gerado pela LLM. Temos muito mais informa√ß√µes nessa resposta, como por exemplo:\n",
    "- Se usa √°udio ou imagem\n",
    "- Filtragem de conte√∫do\n",
    "- Avalia√ß√£o de conte√∫do\n",
    "- Contagem de tokens do prompt\n",
    "- Contagem de tokens gerados na resposta\n",
    "- Detalhes sobre tokens de racioc√≠nio (para modelos que suportam)\n",
    "- Resultados de filtros aplicados\n",
    "\n",
    "Essas informa√ß√µes s√£o essenciais para monitoramento, custos e controle de qualidade da aplica√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e30d33",
   "metadata": {},
   "source": [
    "Ap√≥s realizar a chamada e explorar a resposta, teste voc√™ tamb√©m criando um prompt personalizado. Realize experimentos com os seguintes par√¢metros importantes:\n",
    "\n",
    "- **max_completion_tokens**: N√∫mero m√°ximo de tokens que podem ser gerados na resposta\n",
    "- **temperature**: Controla a criatividade (0.0 = mais determin√≠stico, 1.0 = mais criativo)\n",
    "- **top_p**: Controla a diversidade da resposta via nucleus sampling\n",
    "- **frequency_penalty**: Penaliza repeti√ß√£o de tokens baseado na frequ√™ncia\n",
    "- **presence_penalty**: Penaliza repeti√ß√£o de tokens independentemente da frequ√™ncia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0315241",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Voc√™ √© um assistente √∫til.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Vou viajar para Paris, o que devo ver?\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Paris, a capital da Fran√ßa, √© conhecida por sua arquitetura deslumbrante, museus de arte, marcos hist√≥ricos e atmosfera rom√¢ntica. Aqui est√£o algumas das principais atra√ß√µes para ver em Paris:\\n \\n 1. A Torre Eiffel: A ic√¥nica Torre Eiffel √© um dos marcos mais reconhec√≠veis do mundo e oferece vistas deslumbrantes da cidade.\\n 2. O Museu do Louvre: O Louvre √© um dos maiores e mais famosos museus do mundo, abrigando uma impressionante cole√ß√£o de arte e artefatos, incluindo a Mona Lisa.\\n 3. Catedral de Notre-Dame: Esta bela catedral √© um dos marcos mais famosos de Paris e √© conhecida por sua arquitetura g√≥tica e vitrais deslumbrantes.\\n \\n Estas s√£o apenas algumas das muitas atra√ß√µes que Paris tem a oferecer. Com tanto para ver e fazer, n√£o √© de admirar que Paris seja um dos destinos tur√≠sticos mais populares do mundo.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"O que h√° de t√£o especial no #1?\",\n",
    "        }\n",
    "    ],\n",
    "    max_completion_tokens=800,\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0,\n",
    "    model=deployment_name\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da921c2e",
   "metadata": {},
   "source": [
    "### Exerc√≠cio 3 - Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27f7ec3",
   "metadata": {},
   "source": [
    "Os embeddings s√£o representa√ß√µes num√©ricas de texto que capturam o significado sem√¢ntico das palavras ou frases. No Azure OpenAI, voc√™ pode usar o modelo de embeddings para converter texto em vetores num√©ricos que podem ser usados para tarefas como busca sem√¢ntica, classifica√ß√£o e an√°lise de similaridade.\n",
    "\n",
    "Para mais informa√ß√µes sobre como trabalhar com embeddings no Azure OpenAI, consulte a [documenta√ß√£o oficial](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/embeddings?tabs=python-new)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd62c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.embeddings.create(\n",
    "    input = \"cachorro\",\n",
    "    model= embedding_model\n",
    ")\n",
    "\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeb31ca",
   "metadata": {},
   "source": [
    "Aqui geramos o embedding de uma √∫nica palavra, mas podemos fazer o mesmo para trechos de texto maiores. O modelo organizar√° automaticamente o conte√∫do em vetores num√©ricos que capturam o significado sem√¢ntico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd249d1c",
   "metadata": {},
   "source": [
    "Para armazenar embeddings podemos usar uma s√©rie de servi√ßos dispon√≠veis no Azure. Basta escolher o que mais se adequa √† sua solu√ß√£o:\n",
    "\n",
    "- [Azure AI Search](https://learn.microsoft.com/en-us/azure/search/vector-search-overview)\n",
    "- [Azure Cosmos DB for MongoDB vCore](https://learn.microsoft.com/en-us/azure/cosmos-db/mongodb/vcore/vector-search)\n",
    "- [Azure SQL Database](https://learn.microsoft.com/en-us/azure/azure-sql/database/ai-artificial-intelligence-intelligent-applications?view=azuresql&preserve-view=true#vector-search)\n",
    "- [Azure Cosmos DB for NoSQL](https://learn.microsoft.com/en-us/azure/cosmos-db/vector-search)\n",
    "- [Azure Cosmos DB for PostgreSQL](https://learn.microsoft.com/en-us/azure/cosmos-db/postgresql/howto-use-pgvector)\n",
    "- [Azure Database for PostgreSQL - Flexible Server](https://learn.microsoft.com/en-us/azure/postgresql/flexible-server/how-to-use-pgvector)\n",
    "- [Azure Cache for Redis](https://learn.microsoft.com/en-us/azure/azure-cache-for-redis/cache-tutorial-vector-similarity)\n",
    "- [Use Eventhouse as a vector database - Real-Time Intelligence in Microsoft Fabric](https://learn.microsoft.com/en-us/fabric/real-time-intelligence/vector-database)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447d5fa7",
   "metadata": {},
   "source": [
    "### Exerc√≠cio 4 - Processamento de Imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0534223",
   "metadata": {},
   "source": [
    "No Azure AI Foundry podemos trabalhar com modelos que processam imagens, tanto para gera√ß√£o de imagens quanto modelos multimodais nos quais podemos usar imagens como contexto. Neste exerc√≠cio vamos aprender como utilizar imagens como contexto do prompt.\n",
    "\n",
    "**Primeiro ponto importante**: temos que pensar em como enviar uma imagem junto ao prompt. Para isso temos 2 op√ß√µes principais:\n",
    "1. Enviar a imagem junto com o prompt via base64 (codificada)\n",
    "2. Enviar a imagem como um link/URL\n",
    "\n",
    "Vamos ver os 2 exemplos pr√°ticos a seguir.\n",
    "\n",
    "Primeiro, vamos aproveitar o cliente que j√° instanciamos e enviar uma URL de uma imagem, pedindo para o modelo descrev√™-la:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e0f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Itaim_Bibi_Business_District.jpg/250px-Itaim_Bibi_Business_District.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cb1d42",
   "metadata": {},
   "source": [
    "\n",
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Itaim_Bibi_Business_District.jpg/250px-Itaim_Bibi_Business_District.jpg\" alt=\"Azure AI Foundry\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f371ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        { \"role\": \"system\", \"content\": \"Voc√™ √© um assistente √∫til.\" },\n",
    "        { \"role\": \"user\", \"content\": [  \n",
    "            { \n",
    "                \"type\": \"text\", \n",
    "                \"text\": \"Descreva essa imagem:\" \n",
    "            },\n",
    "            { \n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": image_url\n",
    "                }\n",
    "            }\n",
    "        ] } \n",
    "    ],\n",
    "    max_tokens=2000 \n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20495db6",
   "metadata": {},
   "source": [
    "Agora vamos ler uma imagem local armazenada em nosso sistema e envi√°-la junto com a mensagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb92d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from mimetypes import guess_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e59d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_image_to_data_url(image_path):\n",
    "    # Guess the MIME type of the image based on the file extension\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = 'application/octet-stream'  # Default MIME type if none is found\n",
    "\n",
    "    # Read and encode the image file\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # Construct the data URL\n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b95c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"../../../samples/234039841.jpg\"\n",
    "data_url = local_image_to_data_url(image_path)\n",
    "print(\"Data URL:\", data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7209a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        { \"role\": \"system\", \"content\": \"Voc√™ √© um assistente √∫til.\" },\n",
    "        { \"role\": \"user\", \"content\": [  \n",
    "            { \n",
    "                \"type\": \"text\", \n",
    "                \"text\": \"Descreva essa imagem:\" \n",
    "            },\n",
    "            { \n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": data_url\n",
    "                }\n",
    "            }\n",
    "        ] } \n",
    "    ],\n",
    "    max_tokens=2000 \n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eb4452",
   "metadata": {},
   "source": [
    "Utilizando o Azure OpenAI temos acesso a diversos tipos de funcionalidades al√©m das que exploramos aqui. Recomendo navegar e explorar as op√ß√µes dispon√≠veis para entender qual √© a melhor abordagem para sua aplica√ß√£o espec√≠fica:\n",
    "\n",
    "- [Responses API](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/responses)\n",
    "- [Reasoning Models](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/reasoning)\n",
    "- [Chat completions API](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/chatgpt)\n",
    "- [Computer Use](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/computer-use)\n",
    "- [Model router concepts](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/model-router)\n",
    "- [Function calling](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/function-calling)\n",
    "- [Predicted outputs](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/predicted-outputs)\n",
    "- [Prompt caching](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/prompt-caching)\n",
    "- [Structured outputs](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/structured-outputs)\n",
    "- [Vision-enabled chats](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/structured-outputs)\n",
    "- [JSON Mode](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/json-mode)\n",
    "- [Reproducible output](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/reproducible-output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e339935",
   "metadata": {},
   "source": [
    "### Exerc√≠cio 5 - Outros modelos no Azure AI Foundry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841d9392",
   "metadata": {},
   "source": [
    "Atrav√©s do Azure AI Foundry podemos explorar uma s√©rie de modelos dispon√≠veis no [Model Catalog](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/foundry-models-overview). \n",
    "\n",
    "L√° temos acesso a modelos que s√£o disponibilizados pela Microsoft (OpenAI, Meta, Mistral AI, Deepseek, xAI, Black Forest Labs) bem como modelos disponibilizados por parceiros e pela comunidade (Nixtla, AI21, NTT Data, Core42, NVIDIA NIM Microservices, Stability AI). \n",
    "\n",
    "Atrav√©s da documenta√ß√£o fornecida √© poss√≠vel entender a diferen√ßa entre os diferentes modos de disponibiliza√ß√£o dos modelos e como escolher de acordo com seu cen√°rio espec√≠fico.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69a06ee",
   "metadata": {},
   "source": [
    "Agora vamos seguir com um exemplo pr√°tico de como chamar um modelo disponibilizado pelo Azure AI Foundry atrav√©s de uma chamada de chat completion usando uma biblioteca diferente da anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e12962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a91d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-inference azure-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e70958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = os.getenv(\"AZURE_PHI4_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_PHI4_API_KEY\")\n",
    "model_name = os.getenv(\"AZURE_PHI4_DEPLOYMENT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d21217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clientPhi = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(api_key),\n",
    "    api_version=\"2024-05-01-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694aa690",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = clientPhi.complete(\n",
    "    messages=[\n",
    "        SystemMessage(content=\"Voc√™ √© um assistente √∫til.\"),\n",
    "        UserMessage(content=\"Vou viajar para Paris, o que devo ver?\"),\n",
    "    ],\n",
    "    max_tokens=2048,\n",
    "    temperature=0.8,\n",
    "    top_p=0.1,\n",
    "    presence_penalty=0.0,\n",
    "    frequency_penalty=0.0,\n",
    "    model=model_name\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7941d5",
   "metadata": {},
   "source": [
    "## üéØ Atividades Pr√°ticas \n",
    "\n",
    "Agora que voc√™ explorou os conceitos b√°sicos do Azure AI Foundry, vamos praticar com algumas atividades simples e direcionadas para consolidar o aprendizado!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d5ad2",
   "metadata": {},
   "source": [
    "### üìù Atividade 1: Teste de Temperatura\n",
    "**Objetivo**: Entender como a temperatura afeta a criatividade das respostas.\n",
    "\n",
    "Execute o c√≥digo abaixo e observe como o mesmo prompt gera respostas diferentes com temperaturas variadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a292ffab",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Escreva um slogan criativo para uma empresa de tecnologia.\"\n",
    "\n",
    "# Testando diferentes temperaturas\n",
    "temperaturas = [0.1, 0.5, 1.0]\n",
    "\n",
    "for temp in temperaturas:\n",
    "    print(f\"\\nüå°Ô∏è TEMPERATURA: {temp}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Voc√™ √© um assistente criativo de marketing.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temp,\n",
    "        max_completion_tokens=100\n",
    "    )\n",
    "    \n",
    "    print(response.choices[0].message.content)\n",
    "    print(f\"Tokens usados: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbf57e0",
   "metadata": {},
   "source": [
    "### üîç Atividade 2: Compara√ß√£o de Embeddings\n",
    "**Objetivo**: Comparar como palavras similares t√™m embeddings pr√≥ximos.\n",
    "\n",
    "Vamos gerar embeddings para palavras relacionadas e ver seus tamanhos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c1575",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001ffdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Palavras para comparar\n",
    "palavras = [\"gato\", \"felino\", \"cachorro\", \"c√£o\", \"autom√≥vel\", \"carro\"]\n",
    "\n",
    "embeddings_dict = {}\n",
    "\n",
    "print(\"Gerando embeddings para as palavras...\")\n",
    "for palavra in palavras:\n",
    "    response = client.embeddings.create(\n",
    "        input=palavra,\n",
    "        model=embedding_model\n",
    "    )\n",
    "    embedding = response.data[0].embedding\n",
    "    embeddings_dict[palavra] = embedding\n",
    "    print(f\"‚úÖ {palavra}: {len(embedding)} dimens√µes\")\n",
    "\n",
    "print(f\"\\nPrimeiros 5 valores do embedding da palavra 'gato':\")\n",
    "print(embeddings_dict[\"gato\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb7939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para calcular similaridade de cosseno\n",
    "def calcular_similaridade(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Comparando similaridades\n",
    "print(\"üîç Comparando similaridades:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Gato vs Felino\n",
    "sim_gato_felino = calcular_similaridade(embeddings_dict[\"gato\"], embeddings_dict[\"felino\"])\n",
    "print(f\"Gato ‚Üî Felino: {sim_gato_felino:.3f}\")\n",
    "\n",
    "# Cachorro vs C√£o\n",
    "sim_cachorro_cao = calcular_similaridade(embeddings_dict[\"cachorro\"], embeddings_dict[\"c√£o\"])\n",
    "print(f\"Cachorro ‚Üî C√£o: {sim_cachorro_cao:.3f}\")\n",
    "\n",
    "# Autom√≥vel vs Carro\n",
    "sim_auto_carro = calcular_similaridade(embeddings_dict[\"autom√≥vel\"], embeddings_dict[\"carro\"])\n",
    "print(f\"Autom√≥vel ‚Üî Carro: {sim_auto_carro:.3f}\")\n",
    "\n",
    "# Gato vs Carro (deve ser baixa)\n",
    "sim_gato_carro = calcular_similaridade(embeddings_dict[\"gato\"], embeddings_dict[\"carro\"])\n",
    "print(f\"Gato ‚Üî Carro: {sim_gato_carro:.3f}\")\n",
    "\n",
    "print(f\"\\nüí° Palavras similares t√™m similaridade mais alta (pr√≥xima de 1.0)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de733df",
   "metadata": {},
   "source": [
    "### üñºÔ∏è Atividade 3: An√°lise de Imagem com Diferentes Prompts\n",
    "**Objetivo**: Testar como diferentes prompts afetam a an√°lise da mesma imagem.\n",
    "\n",
    "Vamos usar diferentes tipos de perguntas para a mesma imagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa305916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando a mesma imagem com diferentes prompts\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Itaim_Bibi_Business_District.jpg/250px-Itaim_Bibi_Business_District.jpg\"\n",
    "\n",
    "# Diferentes tipos de an√°lise\n",
    "prompts = [\n",
    "    \"Descreva esta imagem em uma frase:\",\n",
    "    \"Que tipo de local √© este?\",\n",
    "    \"Quais cores predominam nesta imagem?\",\n",
    "    \"Esta imagem transmite que sensa√ß√£o?\",\n",
    "    \"Conte os pr√©dios que voc√™ consegue ver:\"\n",
    "]\n",
    "\n",
    "for i, prompt_text in enumerate(prompts, 1):\n",
    "    print(f\"\\nüîç PERGUNTA {i}: {prompt_text}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Voc√™ √© um assistente especializado em an√°lise de imagens.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt_text},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "            ]}\n",
    "        ],\n",
    "        max_tokens=150\n",
    "    )\n",
    "    \n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b6d8ae",
   "metadata": {},
   "source": [
    "### üî¢ Atividade 4: Contador de Tokens\n",
    "**Objetivo**: Entender como o tamanho do prompt afeta o consumo de tokens.\n",
    "\n",
    "Vamos testar prompts de diferentes tamanhos e ver o impacto nos tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ba7972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts de diferentes tamanhos\n",
    "prompts_teste = [\n",
    "    \"Ol√°\",\n",
    "    \"Explique o que √© intelig√™ncia artificial\",\n",
    "    \"Explique detalhadamente o que √© intelig√™ncia artificial, como funciona, suas aplica√ß√µes pr√°ticas, benef√≠cios e desafios para a sociedade moderna\"\n",
    "]\n",
    "\n",
    "print(\"üìä AN√ÅLISE DE CONSUMO DE TOKENS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, prompt in enumerate(prompts_teste, 1):\n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Voc√™ √© um assistente √∫til.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_completion_tokens=100  # Limitando resposta para focar no prompt\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüîç TESTE {i}:\")\n",
    "    print(f\"Prompt: '{prompt[:50]}{'...' if len(prompt) > 50 else ''}'\")\n",
    "    print(f\"Tokens do prompt: {response.usage.prompt_tokens}\")\n",
    "    print(f\"Tokens da resposta: {response.usage.completion_tokens}\")\n",
    "    print(f\"Total de tokens: {response.usage.total_tokens}\")\n",
    "    print(f\"Resposta: {response.choices[0].message.content[:100]}...\")\n",
    "\n",
    "print(\"\\nüí° Prompts maiores consomem mais tokens de entrada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1351a490",
   "metadata": {},
   "source": [
    "### üé≠ Atividade 5: Teste de Personas\n",
    "**Objetivo**: Ver como diferentes personas (system messages) afetam as respostas.\n",
    "\n",
    "Vamos fazer a mesma pergunta para diferentes \"personalidades\" do assistente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3efb557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diferentes personas para testar\n",
    "personas = [\n",
    "    {\"nome\": \"Professor\", \"system\": \"Voc√™ √© um professor universit√°rio que explica conceitos de forma did√°tica e detalhada.\"},\n",
    "    {\"nome\": \"Amigo\", \"system\": \"Voc√™ √© um amigo pr√≥ximo que conversa de forma casual e descontra√≠da.\"},\n",
    "    {\"nome\": \"Especialista\", \"system\": \"Voc√™ √© um especialista t√©cnico que d√° respostas precisas e diretas.\"},\n",
    "    {\"nome\": \"Poeta\", \"system\": \"Voc√™ √© um poeta que responde sempre de forma criativa e art√≠stica.\"}\n",
    "]\n",
    "\n",
    "pergunta = \"O que voc√™ pensa sobre o futuro da tecnologia?\"\n",
    "\n",
    "print(\"üé≠ TESTANDO DIFERENTES PERSONAS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for persona in personas:\n",
    "    print(f\"\\nüë§ PERSONA: {persona['nome']}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": persona[\"system\"]},\n",
    "            {\"role\": \"user\", \"content\": pergunta}\n",
    "        ],\n",
    "        max_completion_tokens=200,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "print(\"\\nüí° O system message define completamente o 'jeito' do assistente!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

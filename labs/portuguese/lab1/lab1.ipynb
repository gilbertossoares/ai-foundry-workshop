{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b30b8379",
   "metadata": {},
   "source": [
    "# Azure AI Foundry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abd7c63",
   "metadata": {},
   "source": [
    "<center><img src=\"../../../images/Azure-AI-Foundry_1600x900.jpg\" alt=\"Azure AI Foundry\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2920c647",
   "metadata": {},
   "source": [
    "## Laboratório 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81dc1f9",
   "metadata": {},
   "source": [
    "Neste laboratório iremos realizar a conexão com o Azure OpenAI e executar diversas tarefas: solicitar respostas da API, usar respostas baseadas em texto, analisar as respostas obtidas, realizar a conversão de texto em embeddings, fazer chamadas à API enviando imagens e também realizar chamadas a outros modelos LLM.\n",
    "\n",
    "O primeiro passo é a validação da configuração das variáveis de ambiente no arquivo `.env` presente na raiz do repositório.\n",
    "\n",
    "Preencha os valores das variáveis de acordo com o solicitado.\n",
    "\n",
    "### Exercício 1 - Chamada à API\n",
    "\n",
    "Vamos realizar a importação das bibliotecas necessárias para o laboratório."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eed29d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c067a964",
   "metadata": {},
   "source": [
    "Vamos carregar as credenciais em variáveis para facilitar o uso no laboratório."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a2059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "api_version=os.getenv(\"API_VERSION\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec7e921",
   "metadata": {},
   "source": [
    "Agora vamos iniciar o client com as credenciais fornecidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561e832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "  azure_endpoint = azure_endpoint[0], \n",
    "  api_key=api_key[0],  \n",
    "  api_version=api_version\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509b0493",
   "metadata": {},
   "source": [
    "Após criarmos o cliente, vamos realizar uma chamada simples onde passaremos:\n",
    "\n",
    "1. Uma mensagem para a role \"system\" definindo o papel da LLM\n",
    "2. Uma pergunta inicial do usuário\n",
    "3. Uma resposta do assistente demonstrando como ele deve responder (exemplo)\n",
    "4. Uma nova pergunta para ele responder baseado no contexto estabelecido anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647af5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=deployment_name, \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Você é um assistente útil.\"},\n",
    "        {\"role\": \"user\", \"content\": \"O Azure OpenAI suporta chaves gerenciadas pelo cliente?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Sim, chaves gerenciadas pelo cliente são suportadas pelo Azure OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Outros serviços do Azure também suportam isso?\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91875481",
   "metadata": {},
   "source": [
    "Agora vamos acessar diretamente a resposta da LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d19bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c4a22a",
   "metadata": {},
   "source": [
    "### Exercício 2 - Analisando a Resposta\n",
    "\n",
    "Agora que fizemos uma chamada para o Azure OpenAI, vamos analisar o conteúdo completo da resposta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da23911",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8718d0a3",
   "metadata": {},
   "source": [
    "Agora vamos estruturar a resposta em um formato mais legível para melhor visualização dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf8cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict = {\n",
    "    \"id\": response.id,\n",
    "    \"model\": response.model,\n",
    "    \"created\": response.created,\n",
    "    \"usage\": {\n",
    "        \"prompt_tokens\": response.usage.prompt_tokens,\n",
    "        \"completion_tokens\": response.usage.completion_tokens,\n",
    "        \"total_tokens\": response.usage.total_tokens\n",
    "    },\n",
    "    \"completion_tokens_details\": {\n",
    "        \"accepted_prediction_tokens\": response.usage.completion_tokens_details.accepted_prediction_tokens,\n",
    "        \"audio_tokens\": response.usage.completion_tokens_details.audio_tokens,\n",
    "        \"reasoning_tokens\": response.usage.completion_tokens_details.reasoning_tokens,\n",
    "        \"rejected_prediction_tokens\": response.usage.completion_tokens_details.rejected_prediction_tokens\n",
    "    },\n",
    "    \"choices\": [{\n",
    "        \"index\": choice.index,\n",
    "        \"message\": {\n",
    "            \"role\": choice.message.role,\n",
    "            \"content\": choice.message.content\n",
    "        },\n",
    "        \"finish_reason\": choice.finish_reason,\n",
    "        \"content_filter_results\": choice.content_filter_results\n",
    "    } for choice in response.choices],\n",
    "    \"prompt_filter_results\": response.prompt_filter_results\n",
    "}\n",
    "\n",
    "print(json.dumps(response_dict, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3502f5f9",
   "metadata": {},
   "source": [
    "A API não responde apenas com o texto gerado pela LLM. Temos muito mais informações nessa resposta, como por exemplo:\n",
    "- Se usa áudio ou imagem\n",
    "- Filtragem de conteúdo\n",
    "- Avaliação de conteúdo\n",
    "- Contagem de tokens do prompt\n",
    "- Contagem de tokens gerados na resposta\n",
    "- Detalhes sobre tokens de raciocínio (para modelos que suportam)\n",
    "- Resultados de filtros aplicados\n",
    "\n",
    "Essas informações são essenciais para monitoramento, custos e controle de qualidade da aplicação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e30d33",
   "metadata": {},
   "source": [
    "Após realizar a chamada e explorar a resposta, teste você também criando um prompt personalizado. Realize experimentos com os seguintes parâmetros importantes:\n",
    "\n",
    "- **max_completion_tokens**: Número máximo de tokens que podem ser gerados na resposta\n",
    "- **temperature**: Controla a criatividade (0.0 = mais determinístico, 1.0 = mais criativo)\n",
    "- **top_p**: Controla a diversidade da resposta via nucleus sampling\n",
    "- **frequency_penalty**: Penaliza repetição de tokens baseado na frequência\n",
    "- **presence_penalty**: Penaliza repetição de tokens independentemente da frequência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0315241",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Você é um assistente útil.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Vou viajar para Paris, o que devo ver?\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Paris, a capital da França, é conhecida por sua arquitetura deslumbrante, museus de arte, marcos históricos e atmosfera romântica. Aqui estão algumas das principais atrações para ver em Paris:\\n \\n 1. A Torre Eiffel: A icônica Torre Eiffel é um dos marcos mais reconhecíveis do mundo e oferece vistas deslumbrantes da cidade.\\n 2. O Museu do Louvre: O Louvre é um dos maiores e mais famosos museus do mundo, abrigando uma impressionante coleção de arte e artefatos, incluindo a Mona Lisa.\\n 3. Catedral de Notre-Dame: Esta bela catedral é um dos marcos mais famosos de Paris e é conhecida por sua arquitetura gótica e vitrais deslumbrantes.\\n \\n Estas são apenas algumas das muitas atrações que Paris tem a oferecer. Com tanto para ver e fazer, não é de admirar que Paris seja um dos destinos turísticos mais populares do mundo.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"O que há de tão especial no #1?\",\n",
    "        }\n",
    "    ],\n",
    "    max_completion_tokens=800,\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0,\n",
    "    model=deployment_name\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da921c2e",
   "metadata": {},
   "source": [
    "### Exercício 3 - Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27f7ec3",
   "metadata": {},
   "source": [
    "Os embeddings são representações numéricas de texto que capturam o significado semântico das palavras ou frases. No Azure OpenAI, você pode usar o modelo de embeddings para converter texto em vetores numéricos que podem ser usados para tarefas como busca semântica, classificação e análise de similaridade.\n",
    "\n",
    "Para mais informações sobre como trabalhar com embeddings no Azure OpenAI, consulte a [documentação oficial](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/embeddings?tabs=python-new)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd62c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.embeddings.create(\n",
    "    input = \"cachorro\",\n",
    "    model= embedding_model\n",
    ")\n",
    "\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeb31ca",
   "metadata": {},
   "source": [
    "Aqui geramos o embedding de uma única palavra, mas podemos fazer o mesmo para trechos de texto maiores. O modelo organizará automaticamente o conteúdo em vetores numéricos que capturam o significado semântico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd249d1c",
   "metadata": {},
   "source": [
    "Para armazenar embeddings podemos usar uma série de serviços disponíveis no Azure. Basta escolher o que mais se adequa à sua solução:\n",
    "\n",
    "- [Azure AI Search](https://learn.microsoft.com/en-us/azure/search/vector-search-overview)\n",
    "- [Azure Cosmos DB for MongoDB vCore](https://learn.microsoft.com/en-us/azure/cosmos-db/mongodb/vcore/vector-search)\n",
    "- [Azure SQL Database](https://learn.microsoft.com/en-us/azure/azure-sql/database/ai-artificial-intelligence-intelligent-applications?view=azuresql&preserve-view=true#vector-search)\n",
    "- [Azure Cosmos DB for NoSQL](https://learn.microsoft.com/en-us/azure/cosmos-db/vector-search)\n",
    "- [Azure Cosmos DB for PostgreSQL](https://learn.microsoft.com/en-us/azure/cosmos-db/postgresql/howto-use-pgvector)\n",
    "- [Azure Database for PostgreSQL - Flexible Server](https://learn.microsoft.com/en-us/azure/postgresql/flexible-server/how-to-use-pgvector)\n",
    "- [Azure Cache for Redis](https://learn.microsoft.com/en-us/azure/azure-cache-for-redis/cache-tutorial-vector-similarity)\n",
    "- [Use Eventhouse as a vector database - Real-Time Intelligence in Microsoft Fabric](https://learn.microsoft.com/en-us/fabric/real-time-intelligence/vector-database)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447d5fa7",
   "metadata": {},
   "source": [
    "### Exercício 4 - Processamento de Imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0534223",
   "metadata": {},
   "source": [
    "No Azure AI Foundry podemos trabalhar com modelos que processam imagens, tanto para geração de imagens quanto modelos multimodais nos quais podemos usar imagens como contexto. Neste exercício vamos aprender como utilizar imagens como contexto do prompt.\n",
    "\n",
    "**Primeiro ponto importante**: temos que pensar em como enviar uma imagem junto ao prompt. Para isso temos 2 opções principais:\n",
    "1. Enviar a imagem junto com o prompt via base64 (codificada)\n",
    "2. Enviar a imagem como um link/URL\n",
    "\n",
    "Vamos ver os 2 exemplos práticos a seguir.\n",
    "\n",
    "Primeiro, vamos aproveitar o cliente que já instanciamos e enviar uma URL de uma imagem, pedindo para o modelo descrevê-la:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e0f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Itaim_Bibi_Business_District.jpg/250px-Itaim_Bibi_Business_District.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f371ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        { \"role\": \"system\", \"content\": \"Você é um assistente útil.\" },\n",
    "        { \"role\": \"user\", \"content\": [  \n",
    "            { \n",
    "                \"type\": \"text\", \n",
    "                \"text\": \"Descreva essa imagem:\" \n",
    "            },\n",
    "            { \n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": image_url\n",
    "                }\n",
    "            }\n",
    "        ] } \n",
    "    ],\n",
    "    max_tokens=2000 \n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20495db6",
   "metadata": {},
   "source": [
    "Agora vamos ler uma imagem local armazenada em nosso sistema e enviá-la junto com a mensagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb92d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from mimetypes import guess_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e59d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_image_to_data_url(image_path):\n",
    "    # Guess the MIME type of the image based on the file extension\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = 'application/octet-stream'  # Default MIME type if none is found\n",
    "\n",
    "    # Read and encode the image file\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # Construct the data URL\n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b95c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"../../../samples/234039841.jpg\"\n",
    "data_url = local_image_to_data_url(image_path)\n",
    "print(\"Data URL:\", data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7209a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        { \"role\": \"system\", \"content\": \"Você é um assistente útil.\" },\n",
    "        { \"role\": \"user\", \"content\": [  \n",
    "            { \n",
    "                \"type\": \"text\", \n",
    "                \"text\": \"Descreva essa imagem:\" \n",
    "            },\n",
    "            { \n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": data_url\n",
    "                }\n",
    "            }\n",
    "        ] } \n",
    "    ],\n",
    "    max_tokens=2000 \n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eb4452",
   "metadata": {},
   "source": [
    "Utilizando o Azure OpenAI temos acesso a diversos tipos de funcionalidades além das que exploramos aqui. Recomendo navegar e explorar as opções disponíveis para entender qual é a melhor abordagem para sua aplicação específica:\n",
    "\n",
    "- [Responses API](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/responses)\n",
    "- [Reasoning Models](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/reasoning)\n",
    "- [Chat completions API](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/chatgpt)\n",
    "- [Computer Use](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/computer-use)\n",
    "- [Model router concepts](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/model-router)\n",
    "- [Function calling](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/function-calling)\n",
    "- [Predicted outputs](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/predicted-outputs)\n",
    "- [Prompt caching](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/prompt-caching)\n",
    "- [Structured outputs](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/structured-outputs)\n",
    "- [Vision-enabled chats](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/structured-outputs)\n",
    "- [JSON Mode](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/json-mode)\n",
    "- [Reproducible output](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/reproducible-output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e339935",
   "metadata": {},
   "source": [
    "### Exercício 5 - Outros modelos no Azure AI Foundry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841d9392",
   "metadata": {},
   "source": [
    "Através do Azure AI Foundry podemos explorar uma série de modelos disponíveis no [Model Catalog](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/foundry-models-overview). \n",
    "\n",
    "Lá temos acesso a modelos que são disponibilizados pela Microsoft (OpenAI, Meta, Mistral AI, Deepseek, xAI, Black Forest Labs) bem como modelos disponibilizados por parceiros e pela comunidade (Nixtla, AI21, NTT Data, Core42, NVIDIA NIM Microservices, Stability AI). \n",
    "\n",
    "Através da documentação fornecida é possível entender a diferença entre os diferentes modos de disponibilização dos modelos e como escolher de acordo com seu cenário específico.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69a06ee",
   "metadata": {},
   "source": [
    "Agora vamos seguir com um exemplo prático de como chamar um modelo disponibilizado pelo Azure AI Foundry através de uma chamada de chat completion usando uma biblioteca diferente da anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e12962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e70958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = os.getenv(\"AZURE_PHI4_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_PHI4_API_KEY\")\n",
    "model_name = os.getenv(\"AZURE_PHI4_DEPLOYMENT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d21217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clientPhi = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(api_key),\n",
    "    api_version=os.getenv(\"AZURE_PHI4_API_VERSION\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694aa690",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = clientPhi.complete(\n",
    "    messages=[\n",
    "        SystemMessage(content=\"Você é um assistente útil.\"),\n",
    "        UserMessage(content=\"Vou viajar para Paris, o que devo ver?\"),\n",
    "    ],\n",
    "    max_tokens=2048,\n",
    "    temperature=0.8,\n",
    "    top_p=0.1,\n",
    "    presence_penalty=0.0,\n",
    "    frequency_penalty=0.0,\n",
    "    model=model_name\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7941d5",
   "metadata": {},
   "source": [
    "## 🎯 Atividades Práticas \n",
    "\n",
    "Agora que você explorou os conceitos básicos do Azure AI Foundry, vamos praticar com algumas atividades simples e direcionadas para consolidar o aprendizado!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d5ad2",
   "metadata": {},
   "source": [
    "### 📝 Atividade 1: Teste de Temperatura\n",
    "**Objetivo**: Entender como a temperatura afeta a criatividade das respostas.\n",
    "\n",
    "Execute o código abaixo e observe como o mesmo prompt gera respostas diferentes com temperaturas variadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a292ffab",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Escreva um slogan criativo para uma empresa de tecnologia.\"\n",
    "\n",
    "# Testando diferentes temperaturas\n",
    "temperaturas = [0.1, 0.5, 1.0]\n",
    "\n",
    "for temp in temperaturas:\n",
    "    print(f\"\\n🌡️ TEMPERATURA: {temp}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Você é um assistente criativo de marketing.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temp,\n",
    "        max_completion_tokens=100\n",
    "    )\n",
    "    \n",
    "    print(response.choices[0].message.content)\n",
    "    print(f\"Tokens usados: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbf57e0",
   "metadata": {},
   "source": [
    "### 🔍 Atividade 2: Comparação de Embeddings\n",
    "**Objetivo**: Comparar como palavras similares têm embeddings próximos.\n",
    "\n",
    "Vamos gerar embeddings para palavras relacionadas e ver seus tamanhos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001ffdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Palavras para comparar\n",
    "palavras = [\"gato\", \"felino\", \"cachorro\", \"cão\", \"automóvel\", \"carro\"]\n",
    "\n",
    "embeddings_dict = {}\n",
    "\n",
    "print(\"Gerando embeddings para as palavras...\")\n",
    "for palavra in palavras:\n",
    "    response = client.embeddings.create(\n",
    "        input=palavra,\n",
    "        model=embedding_model\n",
    "    )\n",
    "    embedding = response.data[0].embedding\n",
    "    embeddings_dict[palavra] = embedding\n",
    "    print(f\"✅ {palavra}: {len(embedding)} dimensões\")\n",
    "\n",
    "print(f\"\\nPrimeiros 5 valores do embedding da palavra 'gato':\")\n",
    "print(embeddings_dict[\"gato\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb7939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular similaridade de cosseno\n",
    "def calcular_similaridade(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Comparando similaridades\n",
    "print(\"🔍 Comparando similaridades:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Gato vs Felino\n",
    "sim_gato_felino = calcular_similaridade(embeddings_dict[\"gato\"], embeddings_dict[\"felino\"])\n",
    "print(f\"Gato ↔ Felino: {sim_gato_felino:.3f}\")\n",
    "\n",
    "# Cachorro vs Cão\n",
    "sim_cachorro_cao = calcular_similaridade(embeddings_dict[\"cachorro\"], embeddings_dict[\"cão\"])\n",
    "print(f\"Cachorro ↔ Cão: {sim_cachorro_cao:.3f}\")\n",
    "\n",
    "# Automóvel vs Carro\n",
    "sim_auto_carro = calcular_similaridade(embeddings_dict[\"automóvel\"], embeddings_dict[\"carro\"])\n",
    "print(f\"Automóvel ↔ Carro: {sim_auto_carro:.3f}\")\n",
    "\n",
    "# Gato vs Carro (deve ser baixa)\n",
    "sim_gato_carro = calcular_similaridade(embeddings_dict[\"gato\"], embeddings_dict[\"carro\"])\n",
    "print(f\"Gato ↔ Carro: {sim_gato_carro:.3f}\")\n",
    "\n",
    "print(f\"\\n💡 Palavras similares têm similaridade mais alta (próxima de 1.0)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de733df",
   "metadata": {},
   "source": [
    "### 🖼️ Atividade 3: Análise de Imagem com Diferentes Prompts\n",
    "**Objetivo**: Testar como diferentes prompts afetam a análise da mesma imagem.\n",
    "\n",
    "Vamos usar diferentes tipos de perguntas para a mesma imagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa305916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando a mesma imagem com diferentes prompts\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Itaim_Bibi_Business_District.jpg/250px-Itaim_Bibi_Business_District.jpg\"\n",
    "\n",
    "# Diferentes tipos de análise\n",
    "prompts = [\n",
    "    \"Descreva esta imagem em uma frase:\",\n",
    "    \"Que tipo de local é este?\",\n",
    "    \"Quais cores predominam nesta imagem?\",\n",
    "    \"Esta imagem transmite que sensação?\",\n",
    "    \"Conte os prédios que você consegue ver:\"\n",
    "]\n",
    "\n",
    "for i, prompt_text in enumerate(prompts, 1):\n",
    "    print(f\"\\n🔍 PERGUNTA {i}: {prompt_text}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Você é um assistente especializado em análise de imagens.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt_text},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "            ]}\n",
    "        ],\n",
    "        max_tokens=150\n",
    "    )\n",
    "    \n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b6d8ae",
   "metadata": {},
   "source": [
    "### 🔢 Atividade 4: Contador de Tokens\n",
    "**Objetivo**: Entender como o tamanho do prompt afeta o consumo de tokens.\n",
    "\n",
    "Vamos testar prompts de diferentes tamanhos e ver o impacto nos tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ba7972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts de diferentes tamanhos\n",
    "prompts_teste = [\n",
    "    \"Olá\",\n",
    "    \"Explique o que é inteligência artificial\",\n",
    "    \"Explique detalhadamente o que é inteligência artificial, como funciona, suas aplicações práticas, benefícios e desafios para a sociedade moderna\"\n",
    "]\n",
    "\n",
    "print(\"📊 ANÁLISE DE CONSUMO DE TOKENS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, prompt in enumerate(prompts_teste, 1):\n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Você é um assistente útil.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_completion_tokens=100  # Limitando resposta para focar no prompt\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n🔍 TESTE {i}:\")\n",
    "    print(f\"Prompt: '{prompt[:50]}{'...' if len(prompt) > 50 else ''}'\")\n",
    "    print(f\"Tokens do prompt: {response.usage.prompt_tokens}\")\n",
    "    print(f\"Tokens da resposta: {response.usage.completion_tokens}\")\n",
    "    print(f\"Total de tokens: {response.usage.total_tokens}\")\n",
    "    print(f\"Resposta: {response.choices[0].message.content[:100]}...\")\n",
    "\n",
    "print(\"\\n💡 Prompts maiores consomem mais tokens de entrada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1351a490",
   "metadata": {},
   "source": [
    "### 🎭 Atividade 5: Teste de Personas\n",
    "**Objetivo**: Ver como diferentes personas (system messages) afetam as respostas.\n",
    "\n",
    "Vamos fazer a mesma pergunta para diferentes \"personalidades\" do assistente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3efb557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diferentes personas para testar\n",
    "personas = [\n",
    "    {\"nome\": \"Professor\", \"system\": \"Você é um professor universitário que explica conceitos de forma didática e detalhada.\"},\n",
    "    {\"nome\": \"Amigo\", \"system\": \"Você é um amigo próximo que conversa de forma casual e descontraída.\"},\n",
    "    {\"nome\": \"Especialista\", \"system\": \"Você é um especialista técnico que dá respostas precisas e diretas.\"},\n",
    "    {\"nome\": \"Poeta\", \"system\": \"Você é um poeta que responde sempre de forma criativa e artística.\"}\n",
    "]\n",
    "\n",
    "pergunta = \"O que você pensa sobre o futuro da tecnologia?\"\n",
    "\n",
    "print(\"🎭 TESTANDO DIFERENTES PERSONAS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for persona in personas:\n",
    "    print(f\"\\n👤 PERSONA: {persona['nome']}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": persona[\"system\"]},\n",
    "            {\"role\": \"user\", \"content\": pergunta}\n",
    "        ],\n",
    "        max_completion_tokens=200,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "print(\"\\n💡 O system message define completamente o 'jeito' do assistente!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

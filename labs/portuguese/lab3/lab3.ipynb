{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec4fbfc",
   "metadata": {},
   "source": [
    "# Azure AI Foundry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333d0647",
   "metadata": {},
   "source": [
    "<center><img src=\"../../../images/Azure-AI-Foundry_1600x900.jpg\" alt=\"Azure AI Foundry\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0694e061",
   "metadata": {},
   "source": [
    "## Laborat√≥rio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78012a8",
   "metadata": {},
   "source": [
    "### Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d455425",
   "metadata": {},
   "source": [
    "Prompt Engineering √© a arte e ci√™ncia de criar instru√ß√µes eficazes para modelos de linguagem de grande escala (LLMs). √â uma habilidade essencial para obter resultados precisos, relevantes e √∫teis ao interagir com IA generativa.\n",
    "\n",
    "**O que √© Prompt Engineering?**\n",
    "\n",
    "Prompt Engineering envolve o design cuidadoso de instru√ß√µes (prompts) que orientam o comportamento de modelos de IA para produzir sa√≠das desejadas. Isso inclui a escolha de palavras, estrutura√ß√£o de informa√ß√µes, fornecimento de contexto e defini√ß√£o de formatos de sa√≠da.\n",
    "\n",
    "**Por que √© Importante?**\n",
    "\n",
    "- **Precis√£o**: Prompts bem elaborados produzem resultados mais precisos\n",
    "- **Consist√™ncia**: T√©cnicas estruturadas garantem resultados previs√≠veis\n",
    "- **Efici√™ncia**: Reduz a necessidade de m√∫ltiplas tentativas\n",
    "- **Controle**: Permite maior controle sobre o estilo e formato da sa√≠da\n",
    "\n",
    "**Componentes de um Bom Prompt:**\n",
    "\n",
    "1. **Contexto**: Informa√ß√µes de fundo relevantes\n",
    "2. **Instru√ß√£o**: O que voc√™ quer que o modelo fa√ßa\n",
    "3. **Exemplos**: Demonstra√ß√µes do formato desejado (quando aplic√°vel)\n",
    "4. **Limita√ß√µes**: Restri√ß√µes ou diretrizes espec√≠ficas\n",
    "5. **Formato de Sa√≠da**: Como a resposta deve ser estruturada\n",
    "\n",
    "Nas se√ß√µes seguintes, exploraremos v√°rias t√©cnicas avan√ßadas de Prompt Engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa8df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√£o do Azure OpenAI\n",
    "import json\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carrega as vari√°veis de ambiente\n",
    "load_dotenv(dotenv_path=\"../../../.env\")\n",
    "\n",
    "# Configura√ß√µes\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "api_version = os.getenv(\"API_VERSION\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "\n",
    "# Inicializa o cliente\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=azure_endpoint, \n",
    "    api_key=api_key,  \n",
    "    api_version=api_version\n",
    ")\n",
    "\n",
    "print(\"Cliente Azure OpenAI configurado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09db70a",
   "metadata": {},
   "source": [
    "### Zero-Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e70e2c7",
   "metadata": {},
   "source": [
    "Zero-Shot Prompting √© uma t√©cnica onde voc√™ fornece uma tarefa ao modelo de linguagem sem exemplos pr√©vios. O modelo deve entender e executar a tarefa baseado apenas em sua compreens√£o geral e conhecimento pr√©-treinado.\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- N√£o requer exemplos de entrada/sa√≠da\n",
    "- Depende do conhecimento pr√©-treinado do modelo\n",
    "- Simples de implementar\n",
    "- Pode n√£o ser eficaz para tarefas complexas ou espec√≠ficas\n",
    "\n",
    "**Exemplo:**\n",
    "```\n",
    "Prompt: \"Traduza a seguinte frase para o ingl√™s: 'Ol√°, como voc√™ est√°?'\"\n",
    "Resposta: \"Hello, how are you?\"\n",
    "```\n",
    "\n",
    "**Quando usar:**\n",
    "- Tarefas simples e bem definidas\n",
    "- Quando voc√™ n√£o tem exemplos dispon√≠veis\n",
    "- Para teste inicial de capacidades do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1207fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo pr√°tico de Zero-Shot Prompting\n",
    "print(\"=== TESTE: Zero-Shot Prompting ===\")\n",
    "\n",
    "# Exemplo 1: Tradu√ß√£o\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Traduza a seguinte frase para o ingl√™s: 'Ol√°, como voc√™ est√°?'\"}\n",
    "    ],\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "print(\"Tradu√ß√£o:\")\n",
    "print(response.choices[0].message.content)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Exemplo 2: Classifica√ß√£o de sentimento\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Classifique o sentimento desta frase como positivo, negativo ou neutro: 'Este produto √© incr√≠vel, recomendo muito!'\"}\n",
    "    ],\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "print(\"Classifica√ß√£o de sentimento:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b7f0c2",
   "metadata": {},
   "source": [
    "### Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66942a38",
   "metadata": {},
   "source": [
    "Few-Shot Prompting √© uma t√©cnica onde voc√™ fornece alguns exemplos de entrada e sa√≠da esperada antes de apresentar a tarefa real. Isso ajuda o modelo a entender melhor o padr√£o e formato desejado da resposta.\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- Inclui 2-5 exemplos demonstrativos\n",
    "- Melhora a precis√£o em compara√ß√£o ao zero-shot\n",
    "- Ajuda o modelo a entender o formato de sa√≠da\n",
    "- Eficaz para tarefas que seguem padr√µes espec√≠ficos\n",
    "\n",
    "**Exemplo:**\n",
    "```\n",
    "Prompt: \n",
    "\"Classifique o sentimento das seguintes frases:\n",
    "Frase: 'Eu amo este produto!' ‚Üí Sentimento: Positivo\n",
    "Frase: 'Este servi√ßo √© terr√≠vel.' ‚Üí Sentimento: Negativo\n",
    "Frase: 'O produto est√° ok.' ‚Üí Sentimento: Neutro\n",
    "Frase: 'Estou muito feliz com a compra!' ‚Üí Sentimento: ?\"\n",
    "```\n",
    "\n",
    "**Quando usar:**\n",
    "- Tarefas que requerem formato espec√≠fico\n",
    "- Quando zero-shot n√£o fornece resultados adequados\n",
    "- Para classifica√ß√£o ou tarefas estruturadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158edfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo pr√°tico de Few-Shot Prompting\n",
    "print(\"=== TESTE: Few-Shot Prompting ===\")\n",
    "\n",
    "# Exemplo: Classifica√ß√£o de sentimentos com exemplos\n",
    "few_shot_prompt = \"\"\"Classifique o sentimento das seguintes frases:\n",
    "\n",
    "Frase: 'Eu amo este produto!' ‚Üí Sentimento: Positivo\n",
    "Frase: 'Este servi√ßo √© terr√≠vel.' ‚Üí Sentimento: Negativo  \n",
    "Frase: 'O produto est√° ok.' ‚Üí Sentimento: Neutro\n",
    "Frase: 'N√£o consegui usar o aplicativo, muito confuso.' ‚Üí Sentimento: Negativo\n",
    "Frase: 'Funcionou perfeitamente, exatamente como esperado!' ‚Üí Sentimento: Positivo\n",
    "\n",
    "Frase: 'O atendimento foi razo√°vel, nada demais.' ‚Üí Sentimento: ?\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": few_shot_prompt}\n",
    "    ],\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "print(\"Classifica√ß√£o com Few-Shot:\")\n",
    "print(response.choices[0].message.content)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Exemplo 2: Formata√ß√£o de dados com exemplos\n",
    "format_prompt = \"\"\"Converta os dados para o formato especificado:\n",
    "\n",
    "Nome: Jo√£o Silva, Idade: 30, Cidade: S√£o Paulo ‚Üí {\"nome\": \"Jo√£o Silva\", \"idade\": 30, \"cidade\": \"S√£o Paulo\"}\n",
    "Nome: Maria Santos, Idade: 25, Cidade: Rio de Janeiro ‚Üí {\"nome\": \"Maria Santos\", \"idade\": 25, \"cidade\": \"Rio de Janeiro\"}\n",
    "Nome: Pedro Costa, Idade: 45, Cidade: Belo Horizonte ‚Üí {\"nome\": \"Pedro Costa\", \"idade\": 45, \"cidade\": \"Belo Horizonte\"}\n",
    "\n",
    "Nome: Ana Oliveira, Idade: 28, Cidade: Bras√≠lia ‚Üí ?\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": format_prompt}\n",
    "    ],\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "print(\"Formata√ß√£o com Few-Shot:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71159cc",
   "metadata": {},
   "source": [
    "### Chain-of-Thought Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332abde8",
   "metadata": {},
   "source": [
    "Chain-of-Thought (CoT) Prompting √© uma t√©cnica que encoraja o modelo a mostrar seu racioc√≠nio passo a passo antes de chegar √† resposta final. Isso melhora significativamente a performance em tarefas de racioc√≠nio complexo.\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- Quebra problemas complexos em etapas menores\n",
    "- Mostra o processo de racioc√≠nio\n",
    "- Melhora a precis√£o em problemas matem√°ticos e l√≥gicos\n",
    "- Permite identificar onde o racioc√≠nio pode ter falhado\n",
    "\n",
    "**Exemplo:**\n",
    "```\n",
    "Prompt: \"Resolva passo a passo: Se um trem viaja a 60 km/h e precisa percorrer 180 km, quanto tempo levar√°?\n",
    "\n",
    "Vamos pensar passo a passo:\n",
    "1. Velocidade = 60 km/h\n",
    "2. Dist√¢ncia = 180 km\n",
    "3. Tempo = Dist√¢ncia √∑ Velocidade\n",
    "4. Tempo = 180 √∑ 60 = 3 horas\n",
    "\n",
    "Resposta: 3 horas\"\n",
    "```\n",
    "\n",
    "**Quando usar:**\n",
    "- Problemas matem√°ticos ou l√≥gicos\n",
    "- Tarefas que requerem racioc√≠nio multi-etapas\n",
    "- Quando voc√™ precisa verificar o processo de pensamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64065cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo pr√°tico de Chain-of-Thought Prompting\n",
    "print(\"=== TESTE: Chain-of-Thought Prompting ===\")\n",
    "\n",
    "# Exemplo 1: Problema matem√°tico\n",
    "cot_prompt = \"\"\"Resolva passo a passo: \n",
    "\n",
    "Em uma loja, h√° 24 camisetas. 1/3 delas s√£o azuis, 1/4 s√£o vermelhas e o restante s√£o brancas. \n",
    "Se o pre√ßo de cada camiseta azul √© R$ 30, cada vermelha R$ 25 e cada branca R$ 20, qual √© o valor total do estoque?\n",
    "\n",
    "Vamos pensar passo a passo:\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": cot_prompt}\n",
    "    ],\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "print(\"Solu√ß√£o com Chain-of-Thought:\")\n",
    "print(response.choices[0].message.content)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Exemplo 2: Problema l√≥gico\n",
    "logic_prompt = \"\"\"Resolva este problema de l√≥gica passo a passo:\n",
    "\n",
    "Ana, Bruno e Carlos est√£o em uma fila. \n",
    "- Ana n√£o est√° na frente\n",
    "- Bruno n√£o est√° no meio\n",
    "- Carlos n√£o est√° atr√°s\n",
    "\n",
    "Qual √© a ordem da fila?\n",
    "\n",
    "Vamos analisar cada pista:\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": logic_prompt}\n",
    "    ],\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "print(\"Solu√ß√£o l√≥gica com Chain-of-Thought:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e37d85a",
   "metadata": {},
   "source": [
    "### Meta Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94905a3d",
   "metadata": {},
   "source": [
    "Meta Prompting √© uma t√©cnica avan√ßada onde o modelo √© instru√≠do a gerar ou melhorar prompts. Essencialmente, voc√™ usa o modelo para criar prompts melhores para ele mesmo ou para outras tarefas.\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- O modelo ajuda a criar prompts mais eficazes\n",
    "- Pode melhorar iterativamente a qualidade dos prompts\n",
    "- √ötil para otimiza√ß√£o autom√°tica de prompts\n",
    "- Requer conhecimento sobre t√©cnicas de prompting\n",
    "\n",
    "**Exemplo:**\n",
    "```\n",
    "Prompt: \"Crie um prompt eficaz para fazer um modelo de IA explicar conceitos cient√≠ficos complexos para crian√ßas de 10 anos. O prompt deve incluir:\n",
    "- Linguagem simples\n",
    "- Analogias adequadas para a idade\n",
    "- Estrutura clara\n",
    "- Elementos interativos\"\n",
    "\n",
    "Resposta: \"Explique [conceito cient√≠fico] para uma crian√ßa de 10 anos. Use palavras simples, compare com coisas que ela conhece do dia a dia, organize em 3 partes principais e fa√ßa perguntas para manter o interesse.\"\n",
    "```\n",
    "\n",
    "**Quando usar:**\n",
    "- Otimiza√ß√£o de prompts existentes\n",
    "- Cria√ß√£o de prompts para tarefas espec√≠ficas\n",
    "- Quando voc√™ precisa de m√∫ltiplas varia√ß√µes de um prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df50e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo pr√°tico de Meta Prompting\n",
    "print(\"=== TESTE: Meta Prompting ===\")\n",
    "\n",
    "# Exemplo 1: Cria√ß√£o de prompt para ensino\n",
    "meta_prompt = \"\"\"Crie um prompt eficaz para fazer um modelo de IA explicar conceitos de programa√ß√£o para iniciantes. O prompt deve incluir:\n",
    "- Linguagem simples e acess√≠vel\n",
    "- Analogias com o mundo real\n",
    "- Estrutura clara e did√°tica  \n",
    "- Exemplos pr√°ticos\n",
    "- Verifica√ß√£o de compreens√£o\n",
    "\n",
    "Forne√ßa apenas o prompt otimizado, sem explica√ß√µes adicionais.\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": meta_prompt}\n",
    "    ],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "generated_prompt = response.choices[0].message.content\n",
    "print(\"Prompt gerado pelo Meta Prompting:\")\n",
    "print(generated_prompt)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Exemplo 2: Testando o prompt gerado\n",
    "test_content = generated_prompt + \"\\n\\nConceito: Vari√°veis em programa√ß√£o\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": test_content}\n",
    "    ],\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "print(\"Teste do prompt gerado:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74ee17a",
   "metadata": {},
   "source": [
    "### Prompt Chaining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79e43cc",
   "metadata": {},
   "source": [
    "Prompt Chaining √© uma t√©cnica onde voc√™ quebra uma tarefa complexa em m√∫ltiplos prompts sequenciais, onde a sa√≠da de um prompt serve como entrada para o pr√≥ximo.\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- Divide tarefas complexas em etapas menores\n",
    "- A sa√≠da de um prompt alimenta o pr√≥ximo\n",
    "- Permite maior controle sobre cada etapa\n",
    "- Reduz a chance de erros em tarefas complexas\n",
    "\n",
    "**Exemplo:**\n",
    "```\n",
    "Prompt 1: \"Analise este texto e identifique os pontos principais: [texto]\"\n",
    "Sa√≠da 1: \"Pontos principais: A, B, C\"\n",
    "\n",
    "Prompt 2: \"Com base nos pontos principais: A, B, C, crie um resumo executivo de 100 palavras\"\n",
    "Sa√≠da 2: [Resumo executivo]\n",
    "\n",
    "Prompt 3: \"Transforme este resumo em uma apresenta√ß√£o de 3 slides: [resumo]\"\n",
    "```\n",
    "\n",
    "**Quando usar:**\n",
    "- Tarefas que envolvem m√∫ltiplas etapas de processamento\n",
    "- Quando voc√™ precisa de controle granular sobre cada fase\n",
    "- Para transforma√ß√£o de dados em m√∫ltiplos formatos\n",
    "- An√°lise complexa que requer valida√ß√£o em cada etapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b41b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo pr√°tico de Prompt Chaining\n",
    "print(\"=== TESTE: Prompt Chaining ===\")\n",
    "\n",
    "# Texto de exemplo para an√°lise\n",
    "texto_exemplo = \"\"\"\n",
    "A intelig√™ncia artificial est√° transformando rapidamente diversos setores da economia. \n",
    "Na √°rea da sa√∫de, algoritmos de machine learning est√£o sendo usados para diagn√≥sticos \n",
    "mais precisos e descoberta de novos medicamentos. No setor financeiro, a IA ajuda na \n",
    "detec√ß√£o de fraudes e an√°lise de riscos. Na educa√ß√£o, sistemas inteligentes personalizam \n",
    "o aprendizado para cada estudante. Entretanto, tamb√©m surgem desafios √©ticos e quest√µes \n",
    "sobre o futuro do trabalho.\n",
    "\"\"\"\n",
    "\n",
    "# Prompt 1: Identificar pontos principais\n",
    "print(\"1. Identificando pontos principais...\")\n",
    "response1 = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"Analise este texto e identifique os 3 pontos principais em formato de lista:\\n\\n{texto_exemplo}\"}\n",
    "    ],\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "pontos_principais = response1.choices[0].message.content\n",
    "print(\"Pontos principais identificados:\")\n",
    "print(pontos_principais)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "\n",
    "# Prompt 2: Criar resumo executivo\n",
    "print(\"2. Criando resumo executivo...\")\n",
    "response2 = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"Com base nos pontos principais identificados:\\n{pontos_principais}\\n\\nCrie um resumo executivo de exatamente 50 palavras.\"}\n",
    "    ],\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "resumo_executivo = response2.choices[0].message.content\n",
    "print(\"Resumo executivo:\")\n",
    "print(resumo_executivo)\n",
    "print(\"\\n\" + \"-\"*30 + \"\\n\")\n",
    "\n",
    "# Prompt 3: Criar apresenta√ß√£o\n",
    "print(\"3. Criando estrutura de apresenta√ß√£o...\")\n",
    "response3 = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"Transforme este resumo em uma estrutura de apresenta√ß√£o de 3 slides com t√≠tulos e t√≥picos:\\n\\n{resumo_executivo}\"}\n",
    "    ],\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "print(\"Estrutura da apresenta√ß√£o:\")\n",
    "print(response3.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3842bfd5",
   "metadata": {},
   "source": [
    "### Tree of Thoughts (ToT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185847f1",
   "metadata": {},
   "source": [
    "Tree of Thoughts (ToT) √© uma t√©cnica avan√ßada que permite ao modelo explorar m√∫ltiplos caminhos de racioc√≠nio simultaneamente, como uma √°rvore de decis√£o, avaliando e escolhendo os melhores caminhos.\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- Explora m√∫ltiplas abordagens simultaneamente\n",
    "- Permite backtracking quando um caminho n√£o funciona\n",
    "- Avalia a qualidade de cada \"pensamento\" ou etapa\n",
    "- Mais robusto que Chain-of-Thought linear\n",
    "\n",
    "**Exemplo:**\n",
    "```\n",
    "Problema: \"Como resolver o conflito entre equipes?\"\n",
    "\n",
    "Pensamento 1: Media√ß√£o direta\n",
    "‚îú‚îÄ‚îÄ Avalia√ß√£o: Pode ser confrontativo\n",
    "‚îú‚îÄ‚îÄ Pr√≥ximo passo: Reuni√£o formal\n",
    "‚îî‚îÄ‚îÄ Resultado esperado: Resolu√ß√£o r√°pida\n",
    "\n",
    "Pensamento 2: Facilita√ß√£o indireta\n",
    "‚îú‚îÄ‚îÄ Avalia√ß√£o: Menos estressante\n",
    "‚îú‚îÄ‚îÄ Pr√≥ximo passo: Conversas individuais\n",
    "‚îî‚îÄ‚îÄ Resultado esperado: Compreens√£o gradual\n",
    "\n",
    "Pensamento 3: Reestrutura√ß√£o de processos\n",
    "‚îú‚îÄ‚îÄ Avalia√ß√£o: Solu√ß√£o sistem√°tica\n",
    "‚îú‚îÄ‚îÄ Pr√≥ximo passo: An√°lise de workflows\n",
    "‚îî‚îÄ‚îÄ Resultado esperado: Preven√ß√£o futura\n",
    "\n",
    "Melhor caminho: Combina√ß√£o de 2 e 3\n",
    "```\n",
    "\n",
    "**Quando usar:**\n",
    "- Problemas complexos com m√∫ltiplas solu√ß√µes poss√≠veis\n",
    "- Quando voc√™ precisa explorar alternativas\n",
    "- Planejamento estrat√©gico e tomada de decis√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87786e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo pr√°tico de Tree of Thoughts (ToT)\n",
    "print(\"=== TESTE: Tree of Thoughts (ToT) ===\")\n",
    "\n",
    "# Problema complexo para an√°lise\n",
    "tot_prompt = \"\"\"Problema: Uma empresa de tecnologia est√° enfrentando alta rotatividade de funcion√°rios (30% ao ano). \n",
    "Como CEO, voc√™ precisa resolver isso rapidamente.\n",
    "\n",
    "Explore 3 abordagens diferentes simultaneamente:\n",
    "\n",
    "ABORDAGEM 1 - Melhoria Salarial:\n",
    "- Avalie: Pr√≥s, contras e viabilidade\n",
    "- Pr√≥ximos passos espec√≠ficos\n",
    "- Resultado esperado\n",
    "\n",
    "ABORDAGEM 2 - Melhoria do Ambiente de Trabalho:\n",
    "- Avalie: Pr√≥s, contras e viabilidade  \n",
    "- Pr√≥ximos passos espec√≠ficos\n",
    "- Resultado esperado\n",
    "\n",
    "ABORDAGEM 3 - Programa de Desenvolvimento:\n",
    "- Avalie: Pr√≥s, contras e viabilidade\n",
    "- Pr√≥ximos passos espec√≠ficos\n",
    "- Resultado esperado\n",
    "\n",
    "AN√ÅLISE FINAL:\n",
    "- Compare as 3 abordagens\n",
    "- Recomende a melhor estrat√©gia ou combina√ß√£o\n",
    "- Justifique sua escolha\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": tot_prompt}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000\n",
    ")\n",
    "\n",
    "print(\"An√°lise Tree of Thoughts:\")\n",
    "print(response.choices[0].message.content)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Exemplo 2: Problema de planejamento\n",
    "planning_prompt = \"\"\"Voc√™ precisa planejar o lan√ßamento de um novo produto mobile app em 6 meses.\n",
    "Explore simultaneamente 3 estrat√©gias de go-to-market:\n",
    "\n",
    "ESTRAT√âGIA A - Lan√ßamento Gradual:\n",
    "- An√°lise de viabilidade: \n",
    "- Recursos necess√°rios:\n",
    "- Riscos e mitiga√ß√µes:\n",
    "\n",
    "ESTRAT√âGIA B - Lan√ßamento Massivo:\n",
    "- An√°lise de viabilidade:\n",
    "- Recursos necess√°rios: \n",
    "- Riscos e mitiga√ß√µes:\n",
    "\n",
    "ESTRAT√âGIA C - Lan√ßamento por Nicho:\n",
    "- An√°lise de viabilidade:\n",
    "- Recursos necess√°rios:\n",
    "- Riscos e mitiga√ß√µes:\n",
    "\n",
    "DECIS√ÉO: Escolha a melhor estrat√©gia baseado na an√°lise.\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": planning_prompt}\n",
    "    ],\n",
    "    temperature=0.6,\n",
    "    max_tokens=800\n",
    ")\n",
    "\n",
    "print(\"Planejamento com Tree of Thoughts:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb968461",
   "metadata": {},
   "source": [
    "### Retrieval Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b0d285",
   "metadata": {},
   "source": [
    "Retrieval Augmented Generation (RAG) √© uma t√©cnica que combina a gera√ß√£o de texto do modelo com a recupera√ß√£o de informa√ß√µes de uma base de conhecimento externa, permitindo respostas mais precisas e atualizadas.\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- Combina gera√ß√£o com recupera√ß√£o de informa√ß√µes\n",
    "- Acessa conhecimento externo e atualizado\n",
    "- Reduz alucina√ß√µes do modelo\n",
    "- Permite citar fontes espec√≠ficas\n",
    "\n",
    "**Componentes do RAG:**\n",
    "1. **Base de Conhecimento**: Documentos, artigos, bases de dados\n",
    "2. **Sistema de Recupera√ß√£o**: Busca informa√ß√µes relevantes\n",
    "3. **Gerador**: Modelo de linguagem que cria a resposta\n",
    "4. **Integra√ß√£o**: Combina informa√ß√µes recuperadas com gera√ß√£o\n",
    "\n",
    "**Exemplo de Processo:**\n",
    "```\n",
    "Pergunta: \"Quais s√£o as novidades do Azure AI em 2024?\"\n",
    "\n",
    "1. Recupera√ß√£o: Busca documentos recentes sobre Azure AI\n",
    "2. Contexto: \"Azure AI Foundry foi lan√ßado em 2024...\"\n",
    "3. Prompt: \"Com base nas informa√ß√µes: [contexto], responda: [pergunta]\"\n",
    "4. Resposta: Gerada com base no contexto recuperado\n",
    "```\n",
    "\n",
    "**Quando usar:**\n",
    "- Quando voc√™ precisa de informa√ß√µes atualizadas\n",
    "- Para reduzir alucina√ß√µes\n",
    "- Em sistemas de Q&A corporativos\n",
    "- Quando o modelo precisa citar fontes espec√≠ficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0232a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo pr√°tico de RAG (Simulado)\n",
    "print(\"=== TESTE: Retrieval Augmented Generation (RAG) ===\")\n",
    "\n",
    "# Simulando uma base de conhecimento (normalmente seria recuperada de um banco de dados vetorial)\n",
    "knowledge_base = \"\"\"\n",
    "DOCUMENTO 1 - Azure AI Foundry (2024):\n",
    "O Azure AI Foundry √© uma plataforma unificada para desenvolvimento de aplica√ß√µes de IA generativa. \n",
    "Lan√ßado em 2024, oferece ferramentas integradas para treinar, avaliar e implantar modelos de IA.\n",
    "Inclui recursos como prompt flow, avalia√ß√£o automatizada e monitoramento de modelos.\n",
    "\n",
    "DOCUMENTO 2 - Azure OpenAI Service:\n",
    "O Azure OpenAI Service fornece acesso aos modelos GPT-4, GPT-3.5-turbo, DALL-E e Codex atrav√©s de APIs REST.\n",
    "Oferece recursos empresariais como redes virtuais, chaves gerenciadas pelo cliente e compliance.\n",
    "Dispon√≠vel em m√∫ltiplas regi√µes com diferentes modelos e capacidades.\n",
    "\n",
    "DOCUMENTO 3 - Prompt Engineering Best Practices:\n",
    "T√©cnicas essenciais incluem few-shot learning, chain-of-thought e prompt chaining.\n",
    "Importante ser espec√≠fico, usar exemplos claros e estruturar bem as instru√ß√µes.\n",
    "A ordem das informa√ß√µes no prompt pode afetar significativamente os resultados.\n",
    "\"\"\"\n",
    "\n",
    "# Pergunta do usu√°rio\n",
    "pergunta = \"Quais s√£o as principais caracter√≠sticas do Azure AI Foundry lan√ßado em 2024?\"\n",
    "\n",
    "# Prompt RAG: Combinando contexto recuperado com a pergunta\n",
    "rag_prompt = f\"\"\"Com base nas informa√ß√µes fornecidas abaixo, responda √† pergunta do usu√°rio de forma precisa e cite as fontes relevantes.\n",
    "\n",
    "CONTEXTO RECUPERADO:\n",
    "{knowledge_base}\n",
    "\n",
    "PERGUNTA: {pergunta}\n",
    "\n",
    "INSTRU√á√ïES:\n",
    "- Use apenas as informa√ß√µes fornecidas no contexto\n",
    "- Cite o documento espec√≠fico quando relevante\n",
    "- Se a informa√ß√£o n√£o estiver dispon√≠vel no contexto, indique claramente\n",
    "- Seja preciso e objetivo na resposta\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": rag_prompt}\n",
    "    ],\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "print(\"Resposta RAG:\")\n",
    "print(response.choices[0].message.content)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Exemplo 2: Pergunta que n√£o est√° no contexto\n",
    "pergunta2 = \"Qual √© o pre√ßo do Azure AI Foundry?\"\n",
    "\n",
    "rag_prompt2 = f\"\"\"Com base nas informa√ß√µes fornecidas abaixo, responda √† pergunta do usu√°rio.\n",
    "\n",
    "CONTEXTO RECUPERADO:\n",
    "{knowledge_base}\n",
    "\n",
    "PERGUNTA: {pergunta2}\n",
    "\n",
    "INSTRU√á√ïES:\n",
    "- Use apenas as informa√ß√µes fornecidas no contexto\n",
    "- Se a informa√ß√£o n√£o estiver dispon√≠vel, responda: \"Informa√ß√£o n√£o encontrada no contexto fornecido\"\n",
    "\"\"\"\n",
    "\n",
    "response2 = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": rag_prompt2}\n",
    "    ],\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "print(\"Teste com informa√ß√£o n√£o dispon√≠vel:\")\n",
    "print(response2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c526786",
   "metadata": {},
   "source": [
    "### Active-Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2031b02a",
   "metadata": {},
   "source": [
    "Active-Prompt √© uma t√©cnica que seleciona automaticamente os exemplos mais √∫teis e informativos para usar em few-shot prompting, baseando-se na incerteza do modelo sobre certas quest√µes.\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- Sele√ß√£o autom√°tica de exemplos mais √∫teis\n",
    "- Baseada na incerteza do modelo\n",
    "- Melhora a efici√™ncia do few-shot learning\n",
    "- Reduz a necessidade de curadoria manual de exemplos\n",
    "\n",
    "**Como Funciona:**\n",
    "1. **An√°lise de Incerteza**: Identifica onde o modelo tem mais d√∫vidas\n",
    "2. **Sele√ß√£o de Exemplos**: Escolhe exemplos que abordam essas incertezas\n",
    "3. **Prompting Adaptativo**: Usa os exemplos mais relevantes para cada consulta\n",
    "4. **Refinamento Cont√≠nuo**: Melhora com base no feedback\n",
    "\n",
    "**Exemplo Conceitual:**\n",
    "```\n",
    "Tarefa: Classifica√ß√£o de sentimentos\n",
    "\n",
    "Modelo identifica incerteza em:\n",
    "- Sarcasmo\n",
    "- Linguagem amb√≠gua\n",
    "- Express√µes culturais\n",
    "\n",
    "Active-Prompt seleciona exemplos que abordam especificamente:\n",
    "- \"Que maravilha, choveu no meu casamento!\" (Sarcasmo ‚Üí Negativo)\n",
    "- \"N√£o sei se gostei...\" (Amb√≠guo ‚Üí Neutro)\n",
    "- \"T√° de boa!\" (Cultural ‚Üí Positivo)\n",
    "```\n",
    "\n",
    "**Quando usar:**\n",
    "- Quando voc√™ tem muitos exemplos dispon√≠veis\n",
    "- Para otimizar automaticamente few-shot prompts\n",
    "- Em dom√≠nios onde a incerteza varia por t√≥pico\n",
    "- Para sistemas adaptativos que melhoram com o uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f9c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo pr√°tico de Active-Prompt (Simulado)\n",
    "print(\"=== TESTE: Active-Prompt ===\")\n",
    "\n",
    "# Simulando o processo de sele√ß√£o de exemplos baseado na incerteza\n",
    "def simulate_active_prompt():\n",
    "    # Pool de exemplos dispon√≠veis\n",
    "    example_pool = [\n",
    "        (\"Que maravilha, choveu no meu casamento!\", \"Negativo\", \"sarcasmo\"),\n",
    "        (\"Este produto √© ok, nada demais.\", \"Neutro\", \"ambiguidade\"),\n",
    "        (\"Adorei a experi√™ncia!\", \"Positivo\", \"direto\"),\n",
    "        (\"T√° de boa esse app!\", \"Positivo\", \"linguagem_informal\"),\n",
    "        (\"N√£o sei se gostei muito...\", \"Neutro\", \"incerteza\"),\n",
    "        (\"Simplesmente fant√°stico!\", \"Positivo\", \"entusiasmo\"),\n",
    "        (\"Podia ser melhor, n√©?\", \"Negativo\", \"cr√≠tica_indireta\")\n",
    "    ]\n",
    "    \n",
    "    # Pergunta que gera incerteza (linguagem informal + sarcasmo potencial)\n",
    "    query = \"T√° massa esse bagulho, viu!\"\n",
    "    \n",
    "    # Active-Prompt seleciona exemplos mais relevantes para casos similares\n",
    "    selected_examples = [\n",
    "        (\"Que maravilha, choveu no meu casamento!\", \"Negativo\"),  # sarcasmo\n",
    "        (\"T√° de boa esse app!\", \"Positivo\"),  # linguagem informal\n",
    "        (\"Podia ser melhor, n√©?\", \"Negativo\")  # tom amb√≠guo\n",
    "    ]\n",
    "    \n",
    "    return query, selected_examples\n",
    "\n",
    "# Executando simula√ß√£o\n",
    "query, selected_examples = simulate_active_prompt()\n",
    "\n",
    "print(\"Exemplo de Active-Prompt em a√ß√£o:\")\n",
    "print(f\"Frase para classificar: '{query}'\")\n",
    "print(\"\\nExemplos selecionados automaticamente baseados na incerteza:\")\n",
    "for i, (frase, sentimento) in enumerate(selected_examples, 1):\n",
    "    print(f\"{i}. '{frase}' ‚Üí {sentimento}\")\n",
    "\n",
    "# Construindo prompt com exemplos selecionados dinamicamente\n",
    "active_prompt = \"Classifique o sentimento (Positivo, Negativo, Neutro) considerando contexto cultural e poss√≠vel sarcasmo:\\n\\n\"\n",
    "\n",
    "for frase, sentimento in selected_examples:\n",
    "    active_prompt += f\"Frase: '{frase}' ‚Üí Sentimento: {sentimento}\\n\"\n",
    "\n",
    "active_prompt += f\"\\nFrase: '{query}' ‚Üí Sentimento: ?\"\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"Prompt constru√≠do dinamicamente:\")\n",
    "print(active_prompt)\n",
    "\n",
    "# Executando classifica√ß√£o\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": active_prompt}\n",
    "    ],\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "print(f\"\\n{'-'*50}\")\n",
    "print(\"Resultado do Active-Prompt:\")\n",
    "print(response.choices[0].message.content)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Compara√ß√£o: mesmo prompt sem Active-Prompt (exemplos gen√©ricos)\n",
    "generic_prompt = \"\"\"Classifique o sentimento (Positivo, Negativo, Neutro):\n",
    "\n",
    "Frase: 'Eu amo este produto!' ‚Üí Sentimento: Positivo\n",
    "Frase: 'Este servi√ßo √© terr√≠vel.' ‚Üí Sentimento: Negativo\n",
    "Frase: 'O produto est√° ok.' ‚Üí Sentimento: Neutro\n",
    "\n",
    "Frase: 'T√° massa esse bagulho, viu!' ‚Üí Sentimento: ?\"\"\"\n",
    "\n",
    "response_generic = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": generic_prompt}\n",
    "    ],\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "print(\"Compara√ß√£o com Few-Shot gen√©rico:\")\n",
    "print(response_generic.choices[0].message.content)\n",
    "print(\"\\nNote: Active-Prompt selecionou exemplos mais relevantes para lidar com linguagem informal e poss√≠vel sarcasmo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc55621",
   "metadata": {},
   "source": [
    "### Melhores Pr√°ticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f05e2fd",
   "metadata": {},
   "source": [
    "**Seja Espec√≠fico.** Deixe o m√≠nimo poss√≠vel para interpreta√ß√£o. Restrinja o espa√ßo operacional.\n",
    "\n",
    "**Seja Descritivo.** Use analogias para tornar as instru√ß√µes mais claras.\n",
    "\n",
    "**Reforce as Instru√ß√µes.** √Äs vezes pode ser necess√°rio se repetir para o modelo. Forne√ßa instru√ß√µes antes e depois do seu conte√∫do principal, use uma instru√ß√£o e uma deixa, etc.\n",
    "\n",
    "**A Ordem Importa.** A ordem em que voc√™ apresenta informa√ß√µes ao modelo pode impactar o resultado. Se voc√™ coloca instru√ß√µes antes do seu conte√∫do (\"resuma o seguinte...\") ou depois (\"resuma o texto acima...\") pode fazer diferen√ßa no resultado. At√© mesmo a ordem dos exemplos few-shot pode importar. Isso √© conhecido como vi√©s de rec√™ncia.\n",
    "\n",
    "**Ofere√ßa uma Alternativa ao Modelo.** √Äs vezes pode ser √∫til dar ao modelo um caminho alternativo se ele n√£o conseguir completar a tarefa atribu√≠da. Por exemplo, ao fazer uma pergunta sobre um texto, voc√™ pode incluir algo como \"responda com 'n√£o encontrado' se a resposta n√£o estiver presente.\" Isso pode ajudar o modelo a evitar gerar respostas falsas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab59629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ √ÅREA DE EXPERIMENTA√á√ÉO\n",
    "# Use este espa√ßo para testar as t√©cnicas de Prompt Engineering\n",
    "\n",
    "# Exemplo: Teste sua pr√≥pria t√©cnica aqui\n",
    "# response = client.chat.completions.create(\n",
    "#     model=deployment_name,\n",
    "#     messages=[\n",
    "#         {\"role\": \"user\", \"content\": \"Seu prompt aqui...\"}\n",
    "#     ],\n",
    "#     temperature=0.5\n",
    "# )\n",
    "# \n",
    "# print(response.choices[0].message.content)\n",
    "\n",
    "# Seu c√≥digo aqui..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

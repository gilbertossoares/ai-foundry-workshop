{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f84e570",
   "metadata": {},
   "source": [
    "# Azure AI Foundry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6739d708",
   "metadata": {},
   "source": [
    "<center><img src=\"../../../images/Azure-AI-Foundry_1600x900.jpg\" alt=\"Azure AI Foundry\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e8a8af",
   "metadata": {},
   "source": [
    "## Lab 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d150b",
   "metadata": {},
   "source": [
    "In this lab we will explore the AI services present in Azure Foundry. This lab will cover the following services:\n",
    "- Speech\n",
    "- Language + Translator\n",
    "- Vision + Document\n",
    "- Content Safety\n",
    "\n",
    "Understanding these services allows us to add more capabilities to our applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7201118",
   "metadata": {},
   "source": [
    "### Exercise 1 - Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3019d64",
   "metadata": {},
   "source": [
    "The Speech service provides speech-to-text and text-to-speech conversion capabilities with a Speech resource. You can transcribe speech to text with high accuracy, produce natural text-to-speech voices, translate spoken audio, and use speaker recognition during conversations. Create custom voices, add specific words to your base vocabulary, or build your own models. Run Speech anywhere, in the cloud or at the edge in containers. It's easy to enable speech in your applications, tools, and devices with the Speech CLI, Speech SDK, and REST APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d328ef9c",
   "metadata": {},
   "source": [
    "Common scenarios for speech usage:\n",
    "\n",
    "**Caption Generation:** Learn how to synchronize captions with your input audio, apply profanity filters, get partial results, apply customizations, and identify spoken languages for multilingual scenarios.\n",
    "\n",
    "**Audio Content Creation:** You can use neural voices to make interactions with chatbots and voice assistants more natural and engaging, convert digital texts like e-books into audiobooks, and enhance automotive navigation systems.\n",
    "\n",
    "**Call Center:** Transcribe calls in real-time or process a batch of calls, remove personally identifiable information, and extract insights like sentiment analysis to assist with your call center use case.\n",
    "\n",
    "**Language Learning:** Provide pronunciation assessment feedback for language learners, offer real-time transcription support for remote learning conversations, and read educational materials aloud using neural voices.\n",
    "\n",
    "**Voice Assistants:** Create natural, human-like conversational interfaces for your applications and experiences. The voice assistant feature offers fast and reliable interaction between a device and an assistant implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e553179c",
   "metadata": {},
   "source": [
    "To perform this exercise, verify that your `.env` file has the following variables filled:\n",
    "- SPEECH_ENDPOINT\n",
    "- SPEECH_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0806a5",
   "metadata": {},
   "source": [
    "After verification, let's start by loading the necessary libraries, initializing the client, and making a call to convert audio to text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-cognitiveservices-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf41328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous speech recognition to process all audio, even with initial silence\n",
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "speech_key = os.getenv('SPEECH_KEY')\n",
    "speech_region = os.getenv('SPEECH_REGION')\n",
    "audio_file = '../../../samples/audio001.wav'\n",
    "if speech_key and speech_region:\n",
    "    try:\n",
    "        speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "        speech_config.speech_recognition_language = \"en-US\"\n",
    "        audio_config = speechsdk.audio.AudioConfig(filename=audio_file)\n",
    "        speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "        recognized_texts = []\n",
    "        def recognized_cb(evt):\n",
    "            if evt.result.text:\n",
    "                print('Recognized:', evt.result.text)\n",
    "                recognized_texts.append(evt.result.text)\n",
    "\n",
    "        speech_recognizer.recognized.connect(recognized_cb)\n",
    "\n",
    "        print(\"Starting continuous recognition...\")\n",
    "        speech_recognizer.start_continuous_recognition()\n",
    "\n",
    "        # Wait for recognition to finish (adjust time according to audio size)\n",
    "        time.sleep(10)\n",
    "        speech_recognizer.stop_continuous_recognition()\n",
    "\n",
    "        print(\"Recognition completed. Full text:\")\n",
    "        print(' '.join(recognized_texts))\n",
    "    except Exception as e:\n",
    "        print(f\"Error in continuous recognition: {e}\")\n",
    "else:\n",
    "    print(\"Please configure the SPEECH_KEY and SPEECH_REGION environment variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca39a6a4",
   "metadata": {},
   "source": [
    "### Exercise 2 - Language + Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1f8577",
   "metadata": {},
   "source": [
    "Integrate natural language into applications, bots, and IoT devices. For example, this service can remove sensitive data, segment long meetings into chapters, analyze health records, and orchestrate conversational bots with your custom intents using factual responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3046ebe",
   "metadata": {},
   "source": [
    "This Language service unifies the following Azure AI services previously available separately: Text Analytics, QnA Maker, and LUIS.\n",
    "\n",
    "Azure AI Foundry allows you to use most of the following service features without needing to write code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2140f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-textanalytics azure-ai-translation-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a6e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language Analytics Example\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.translation.text import TextTranslationClient\n",
    "from azure.ai.translation.text.models import InputTextItem\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Language Analytics\n",
    "language_endpoint = os.getenv('LANGUAGE_ENDPOINT')\n",
    "language_key = os.getenv('LANGUAGE_KEY')\n",
    "\n",
    "# Translator\n",
    "translator_endpoint = os.getenv('TRANSLATOR_ENDPOINT')\n",
    "translator_key = os.getenv('TRANSLATOR_KEY')\n",
    "translator_region = os.getenv('TRANSLATOR_REGION')\n",
    "\n",
    "if language_endpoint and language_key:\n",
    "    try:\n",
    "        print(\"=== Azure AI Language Analytics ===\")\n",
    "        \n",
    "        # Create Language client\n",
    "        text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=language_endpoint,\n",
    "            credential=AzureKeyCredential(language_key)\n",
    "        )\n",
    "        \n",
    "        # Sample texts for analysis\n",
    "        documents = [\n",
    "            \"I absolutely love this new product! It's amazing and works perfectly.\",\n",
    "            \"This service is terrible and I'm very disappointed with the quality.\",\n",
    "            \"The weather today is neutral, neither good nor bad.\"\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nüìä Sentiment Analysis:\")\n",
    "        # Sentiment analysis\n",
    "        sentiment_results = text_analytics_client.analyze_sentiment(documents=documents)\n",
    "        \n",
    "        for idx, result in enumerate(sentiment_results):\n",
    "            if not result.is_error:\n",
    "                print(f\"\\nDocument {idx + 1}: {documents[idx][:50]}...\")\n",
    "                print(f\"Sentiment: {result.sentiment}\")\n",
    "                print(f\"Confidence scores - Positive: {result.confidence_scores.positive:.2f}, \"\n",
    "                      f\"Negative: {result.confidence_scores.negative:.2f}, \"\n",
    "                      f\"Neutral: {result.confidence_scores.neutral:.2f}\")\n",
    "            else:\n",
    "                print(f\"Error in document {idx + 1}: {result.error}\")\n",
    "        \n",
    "        print(\"\\nüè∑Ô∏è Key Phrase Extraction:\")\n",
    "        # Key phrase extraction\n",
    "        key_phrases_results = text_analytics_client.extract_key_phrases(documents=documents)\n",
    "        \n",
    "        for idx, result in enumerate(key_phrases_results):\n",
    "            if not result.is_error:\n",
    "                print(f\"\\nDocument {idx + 1}: {documents[idx][:50]}...\")\n",
    "                print(f\"Key phrases: {', '.join(result.key_phrases)}\")\n",
    "            else:\n",
    "                print(f\"Error in document {idx + 1}: {result.error}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error in language analytics: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Define LANGUAGE_ENDPOINT and LANGUAGE_KEY variables in the .env file\")\n",
    "\n",
    "# Translator\n",
    "if translator_key and translator_region:\n",
    "    try:\n",
    "        print(\"\\n\\n=== Azure AI Translator ===\")\n",
    "        \n",
    "        # Create Translator client\n",
    "        translator_client = TextTranslationClient(\n",
    "            endpoint=translator_endpoint,\n",
    "            credential=AzureKeyCredential(translator_key),\n",
    "            region=translator_region\n",
    "        )\n",
    "        \n",
    "        # Text to translate\n",
    "        source_text = \"Hello, world! This is a test of the Azure AI Translator service.\"\n",
    "        input_text_elements = [InputTextItem(text=source_text)]\n",
    "        \n",
    "        print(f\"\\nüìù Original text: {source_text}\")\n",
    "        print(\"\\nüåç Translations:\")\n",
    "        \n",
    "        # Translate to multiple languages\n",
    "        target_languages = ['pt', 'es', 'fr', 'de', 'ja']\n",
    "        \n",
    "        response = translator_client.translate(\n",
    "            content=input_text_elements,\n",
    "            to=target_languages\n",
    "        )\n",
    "        \n",
    "        for translation_result in response:\n",
    "            for translation in translation_result.translations:\n",
    "                language_names = {\n",
    "                    'pt': 'Portuguese',\n",
    "                    'es': 'Spanish', \n",
    "                    'fr': 'French',\n",
    "                    'de': 'German',\n",
    "                    'ja': 'Japanese'\n",
    "                }\n",
    "                language_name = language_names.get(translation.to, translation.to)\n",
    "                print(f\"  {language_name} ({translation.to}): {translation.text}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error in translator: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Define TRANSLATOR_KEY and TRANSLATOR_REGION variables in the .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61986690",
   "metadata": {},
   "source": [
    "### Exercise 3 - Vision + Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1994f6d2",
   "metadata": {},
   "source": [
    "Azure AI Vision is a unified service that offers innovative computer vision capabilities. Give your apps the ability to analyze images, read text, and detect faces with prebuilt image tagging, text extraction with optical character recognition (OCR), and responsible facial recognition. Incorporate vision features into your projects with no machine learning experience required.\n",
    "\n",
    "**Computer Vision** - Extracts rich information from images to categorize and process visual data.\n",
    "\n",
    "**Face** - The Face service provides AI algorithms that detect, recognize, and analyze human faces in images. Facial recognition software is important in many different scenarios, such as identification, touchless access control, and face blurring for privacy.\n",
    "\n",
    "**Video Retrieval** - Video Retrieval allows you to create an index of videos that you can search with natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961ff78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-vision-imageanalysis azure-ai-formrecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf63d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Configure Vision client\n",
    "vision_endpoint = os.getenv('AZURE_VISION_ENDPOINT')\n",
    "vision_key = os.getenv('AZURE_VISION_KEY')\n",
    "\n",
    "if vision_endpoint and vision_key:\n",
    "    try:\n",
    "        print(\"=== Azure AI Vision - Image Analysis ===\")\n",
    "        \n",
    "        # Create client\n",
    "        client = ImageAnalysisClient(\n",
    "            endpoint=vision_endpoint,\n",
    "            credential=AzureKeyCredential(vision_key)\n",
    "        )\n",
    "        \n",
    "        # Analyze remote image\n",
    "        print(\"\\n1. Analyzing remote image...\")\n",
    "        result = client.analyze_from_url(\n",
    "            image_url=\"https://learn.microsoft.com/azure/ai-services/computer-vision/media/quickstarts/presentation.png\",\n",
    "            visual_features=[VisualFeatures.CAPTION, VisualFeatures.READ],\n",
    "            gender_neutral_caption=True,  # Optional (default is False)\n",
    "        )\n",
    "        \n",
    "        print(\"Analysis results:\")\n",
    "        \n",
    "        # Display caption results\n",
    "        print(\"\\nüìù Caption:\")\n",
    "        if result.caption is not None:\n",
    "            print(f\"   '{result.caption.text}', Confidence: {result.caption.confidence:.4f}\")\n",
    "        else:\n",
    "            print(\"   No caption found\")\n",
    "\n",
    "        # Display OCR results (extracted text)\n",
    "        print(\"\\nüìñ Extracted text (OCR):\")\n",
    "        if result.read is not None:\n",
    "            for block in result.read.blocks:\n",
    "                for line in block.lines:\n",
    "                    print(f\"   Line: '{line.text}', Bounding box: {line.bounding_polygon}\")\n",
    "                    for word in line.words:\n",
    "                        print(f\"     Word: '{word.text}', Confidence: {word.confidence:.4f}\")\n",
    "        else:\n",
    "            print(\"   No text found\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in image analysis: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Define AZURE_VISION_ENDPOINT and AZURE_VISION_KEY variables in the .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d42932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced example - Complete local image analysis\n",
    "if vision_endpoint and vision_key:\n",
    "    try:\n",
    "        print(\"\\n=== Advanced Image Analysis ===\")\n",
    "        \n",
    "        # Analyze local image\n",
    "        image_path = \"../../../samples/car-accident.png\"\n",
    "        \n",
    "        print(f\"\\n2. Analyzing local image: {image_path}\")\n",
    "        \n",
    "        # Open local image\n",
    "        with open(image_path, \"rb\") as image_data:\n",
    "            # Complete analysis with multiple features\n",
    "            result = client.analyze(\n",
    "                image_data=image_data.read(),\n",
    "                visual_features=[\n",
    "                    VisualFeatures.CAPTION,\n",
    "                    VisualFeatures.READ,\n",
    "                    VisualFeatures.TAGS,\n",
    "                    VisualFeatures.OBJECTS,\n",
    "                    VisualFeatures.PEOPLE,\n",
    "                    VisualFeatures.SMART_CROPS\n",
    "                ],\n",
    "                gender_neutral_caption=True\n",
    "            )\n",
    "            \n",
    "            print(\"\\nüìù Caption:\")\n",
    "            if result.caption:\n",
    "                print(f\"   '{result.caption.text}', Confidence: {result.caption.confidence:.4f}\")\n",
    "            \n",
    "            print(\"\\nüè∑Ô∏è Identified tags:\")\n",
    "            if result.tags:\n",
    "                for tag in result.tags.list:\n",
    "                    print(f\"   - {tag.name}: {tag.confidence:.4f}\")\n",
    "            \n",
    "            print(\"\\nüì¶ Detected objects:\")\n",
    "            if result.objects:\n",
    "                for obj in result.objects.list:\n",
    "                    print(f\"   - {obj.tags[0].name}: {obj.tags[0].confidence:.4f}\")\n",
    "                    print(f\"     Location: {obj.bounding_box}\")\n",
    "            \n",
    "            print(\"\\nüë• Detected people:\")\n",
    "            if result.people:\n",
    "                for person in result.people.list:\n",
    "                    print(f\"   - Person detected with confidence: {person.confidence:.4f}\")\n",
    "                    print(f\"     Location: {person.bounding_box}\")\n",
    "            \n",
    "            print(\"\\n‚úÇÔ∏è Smart crops:\")\n",
    "            if result.smart_crops:\n",
    "                for crop in result.smart_crops.list:\n",
    "                    print(f\"   - Aspect {crop.aspect_ratio}: {crop.bounding_box}\")\n",
    "                    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Image file not found: {image_path}\")\n",
    "        print(\"Make sure the file exists at the specified path.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in advanced analysis: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c5a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example - Document Intelligence\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Configure Document Intelligence client\n",
    "doc_intelligence_endpoint = os.getenv('DOC_INTELLIGENCE_ENDPOINT')\n",
    "doc_intelligence_key = os.getenv('DOC_INTELLIGENCE_KEY')\n",
    "\n",
    "if doc_intelligence_endpoint and doc_intelligence_key:\n",
    "    try:\n",
    "        print(\"\\n=== Document Intelligence ===\")\n",
    "        \n",
    "        # Create client\n",
    "        document_analysis_client = DocumentAnalysisClient(\n",
    "            endpoint=doc_intelligence_endpoint,\n",
    "            credential=AzureKeyCredential(doc_intelligence_key)\n",
    "        )\n",
    "        \n",
    "        # Analyze generic document\n",
    "        doc_path = \"../../../samples/placa.jpg\"\n",
    "        \n",
    "        with open(doc_path, \"rb\") as f:\n",
    "            # Use pre-built model for general layout\n",
    "            poller = document_analysis_client.begin_analyze_document(\n",
    "                \"prebuilt-layout\", document=f\n",
    "            )\n",
    "            \n",
    "        result = poller.result()\n",
    "        \n",
    "        print(\"Document Layout Analysis:\")\n",
    "        print(f\"Number of pages: {len(result.pages)}\")\n",
    "        \n",
    "        # Extract tables\n",
    "        if result.tables:\n",
    "            print(f\"\\nTables found: {len(result.tables)}\")\n",
    "            for idx, table in enumerate(result.tables):\n",
    "                print(f\"Table {idx + 1}: {table.row_count} rows x {table.column_count} columns\")\n",
    "                \n",
    "        # Extract paragraphs\n",
    "        if result.paragraphs:\n",
    "            print(f\"\\nParagraphs found: {len(result.paragraphs)}\")\n",
    "            for idx, paragraph in enumerate(result.paragraphs[:3]):  # Show only first 3\n",
    "                print(f\"Paragraph {idx + 1}: {paragraph.content[:100]}...\")\n",
    "                \n",
    "        # Extract key-value pairs\n",
    "        if result.key_value_pairs:\n",
    "            print(f\"\\nKey-value pairs found: {len(result.key_value_pairs)}\")\n",
    "            for kv_pair in result.key_value_pairs[:5]:  # Show only first 5\n",
    "                if kv_pair.key and kv_pair.value:\n",
    "                    print(f\"  {kv_pair.key.content}: {kv_pair.value.content}\")\n",
    "                    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Document file not found: {doc_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Document Intelligence: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Define DOC_INTELLIGENCE_ENDPOINT and DOC_INTELLIGENCE_KEY variables in the .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5821588f",
   "metadata": {},
   "source": [
    "### Exercise 4 - Content Safety"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b4c6a9",
   "metadata": {},
   "source": [
    "Azure AI Content Safety detects harmful user-generated and AI-generated content in applications and services. This service provides several different types of analysis.\n",
    "\n",
    "**Prompt Shields** - Examines text for risks of user input attacks on a Large Language Model.\n",
    "\n",
    "**Groundedness Detection (preview)** - Detects whether text responses from large language models (LLMs) are grounded in the source materials provided by users.\n",
    "\n",
    "**Protected Material Detection in Text** - Examines AI-generated text for known text content (e.g., song lyrics, articles, recipes, selected web content).\n",
    "\n",
    "**Custom Categories API (standard) (preview)** - Allows you to create and train your own custom content categories and examine text for matches.\n",
    "\n",
    "**Custom Categories API (rapid) (preview)** - Allows you to define emerging patterns of harmful content and examine text and images for matches.\n",
    "\n",
    "**Text Analysis API** - Examines text for sexual, violence, hate, and self-harm content with multiple severity levels.\n",
    "\n",
    "**Image Analysis API** - Examines images for sexual, violence, hate, and self-harm content with multiple severity levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba73862",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-contentsafety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3786e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example - Content Safety (following official quickstart)\n",
    "from azure.ai.contentsafety import ContentSafetyClient\n",
    "from azure.ai.contentsafety.models import AnalyzeTextOptions, TextCategory\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "def analyze_text_content(text_to_analyze):\n",
    "    \"\"\"\n",
    "    Function to analyze text using Azure Content Safety\n",
    "    Based on Microsoft's official quickstart\n",
    "    \"\"\"\n",
    "    # Get credentials from environment variables\n",
    "    key = os.getenv('CONTENT_SAFETY_KEY')\n",
    "    endpoint = os.getenv('CONTENT_SAFETY_ENDPOINT')\n",
    "    \n",
    "    if not key or not endpoint:\n",
    "        print(\"‚ùå Error: Define CONTENT_SAFETY_KEY and CONTENT_SAFETY_ENDPOINT variables in the .env file\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Create Azure AI Content Safety client\n",
    "        client = ContentSafetyClient(endpoint, AzureKeyCredential(key))\n",
    "        \n",
    "        # Configure request\n",
    "        request = AnalyzeTextOptions(text=text_to_analyze)\n",
    "        \n",
    "        # Analyze text\n",
    "        response = client.analyze_text(request)\n",
    "        \n",
    "        # Extract results by specific category (following quickstart)\n",
    "        hate_result = next((item for item in response.categories_analysis if item.category == TextCategory.HATE), None)\n",
    "        self_harm_result = next((item for item in response.categories_analysis if item.category == TextCategory.SELF_HARM), None)\n",
    "        sexual_result = next((item for item in response.categories_analysis if item.category == TextCategory.SEXUAL), None)\n",
    "        violence_result = next((item for item in response.categories_analysis if item.category == TextCategory.VIOLENCE), None)\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"üìù Analyzed text: '{text_to_analyze}'\")\n",
    "        print(\"üîç Analysis results:\")\n",
    "        \n",
    "        if hate_result:\n",
    "            print(f\"  üí¨ Hate: Severity {hate_result.severity}\")\n",
    "        if self_harm_result:\n",
    "            print(f\"  ü©π Self-harm: Severity {self_harm_result.severity}\")\n",
    "        if sexual_result:\n",
    "            print(f\"  üîû Sexual: Severity {sexual_result.severity}\")\n",
    "        if violence_result:\n",
    "            print(f\"  ‚öîÔ∏è Violence: Severity {violence_result.severity}\")\n",
    "        \n",
    "        # Interpret overall risk level\n",
    "        max_severity = max([\n",
    "            hate_result.severity if hate_result else 0,\n",
    "            self_harm_result.severity if self_harm_result else 0,\n",
    "            sexual_result.severity if sexual_result else 0,\n",
    "            violence_result.severity if violence_result else 0\n",
    "        ])\n",
    "        \n",
    "        if max_severity == 0:\n",
    "            risk_level = \"‚úÖ Safe\"\n",
    "        elif max_severity <= 2:\n",
    "            risk_level = \"‚ö†Ô∏è Low risk\"\n",
    "        elif max_severity <= 4:\n",
    "            risk_level = \"üî∏ Moderate risk\"\n",
    "        else:\n",
    "            risk_level = \"üî¥ High risk\"\n",
    "            \n",
    "        print(f\"üìä Overall assessment: {risk_level}\")\n",
    "        return response\n",
    "        \n",
    "    except HttpResponseError as e:\n",
    "        print(\"‚ùå Text analysis failed.\")\n",
    "        if e.error:\n",
    "            print(f\"Error code: {e.error.code}\")\n",
    "            print(f\"Error message: {e.error.message}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Unexpected error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Configure Content Safety client\n",
    "content_safety_endpoint = os.getenv('CONTENT_SAFETY_ENDPOINT')\n",
    "content_safety_key = os.getenv('CONTENT_SAFETY_KEY')\n",
    "\n",
    "if content_safety_endpoint and content_safety_key:\n",
    "    print(\"=== Content Safety - Text Analysis ===\")\n",
    "    print(\"Based on Microsoft's official quickstart\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Sample texts for analysis (including different risk levels)\n",
    "    test_texts = [\n",
    "        \"Hello! How are you today? Have a great day!\",\n",
    "        \"This is a neutral text about technology and Python programming.\",\n",
    "        \"I'm very angry about this situation, but I'll resolve it in a civilized manner.\",\n",
    "        \"Test text for potentially problematic content moderation.\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"üìã Analyzing {len(test_texts)} sample texts...\\n\")\n",
    "    \n",
    "    for idx, text in enumerate(test_texts, 1):\n",
    "        print(f\"üîç Analysis {idx}/{len(test_texts)}:\")\n",
    "        result = analyze_text_content(text)\n",
    "        \n",
    "        if result:\n",
    "            print(\"‚úÖ Analysis completed successfully\")\n",
    "        else:\n",
    "            print(\"‚ùå Analysis failed\")\n",
    "            \n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Required configuration:\")\n",
    "    print(\"Define CONTENT_SAFETY_ENDPOINT and CONTENT_SAFETY_KEY variables in the .env file\")\n",
    "    print(\"\\nConfiguration example:\")\n",
    "    print(\"CONTENT_SAFETY_ENDPOINT=https://your-content-safety.cognitiveservices.azure.com/\")\n",
    "    print(\"CONTENT_SAFETY_KEY=your-content-safety-key\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
